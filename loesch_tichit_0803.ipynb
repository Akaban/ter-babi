{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Projet: Facebook BaBi tasks\n",
    "Notebook de la semaine du 08/03\n",
    "Par Thierry Loesch et Bryce TIchit\n",
    "\n",
    "Différents modèles sont étudiés durant cette séance:\n",
    "\n",
    "Les résultats de précision sont pour la première tache.\n",
    "\n",
    "- Modèle symétrique LSTM : Un embedding et un LSTM pour chaque modèle et un merge concat\n",
    "    \n",
    "    Précision: 36%\n",
    "- Modèle LSTM sur le modèle des questions, merge concat puis LSTM sur le modèle fusionné\n",
    "    \n",
    "    Precision: 48%\n",
    "    \n",
    "- Modèle Bi-LSTM avec couche dense en sortie de chaque sous-modèle\n",
    "\n",
    "    Précision: 35%\n",
    "    \n",
    "    \n",
    "Nous avons par la suite modifié le code afin d'implémenter un ensemble de validation, les résultats obtenus sont les suivants,\n",
    "\n",
    "Modèle symétrique LSTM: 36%\n",
    "Modèle LSTM sur les questions: 46% \n",
    "Modèle Bi-LSTM: 36%\n",
    "\n",
    "Par la suite nous avons augmenté la taille des ensembles, (à finir)\n",
    "\n",
    "Modèle LSTM sur les questions: 66%\n",
    "\n",
    "On remarque qu'il n'y a pas de différence de précision selon que l'on utilise un ensemble de validation ou pas, ce qui signifie que nous n'étions pas sujet au sur-apprentissage.\n",
    "\n",
    "\n",
    "# Rappel introduction dernier notebook\n",
    "\n",
    "Sur ce notebook nous avons rajouté un parser afin de parser les données et nous avons fait la vectorisation de celles-ci. Un modèle a aussi été créé selon ce qui nous avions défini dans le notebook précédent. Nous avons ainsi pu commencer a faire des tests avec le modèle, et nous avons eu des résultats plutôt moyens sur la première task, environ 43% de précision. Il nous faut investiguer plus le problème pour améliorer nos performances, peut être en utilisant différents réseaux récurrents. Le réseau récurrent utilisé est LSTM sur ce notebook.\n",
    "\n",
    "Reste à perfectionner le modèle et/ou les autres paramètres. Essayer les autres tasks également. Utiliser un Memory Network pour après?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def tokenize(sent):\n",
    "    return [x.strip() for x in re.split('(\\W+)?', sent) if x.strip()]\n",
    "\n",
    "\n",
    "def parserBabi(data):\n",
    "    ret=list()\n",
    "    story=list()\n",
    "    \n",
    "    for phrase in data:\n",
    "        phrase = phrase.decode('utf-8').strip()\n",
    "        id_phrase,phrase = int(phrase[0]),phrase[1:]\n",
    "        \n",
    "        if id_phrase == 1: #Nouvelle story\n",
    "            story=list()\n",
    "            \n",
    "        if '\\t' in phrase: #Si tabulation alors il s'agit de la question ainsi que de la réponse\n",
    "            q, a, justif = phrase.split('\\t')\n",
    "            q = tokenize(q)\n",
    "            \n",
    "            data_story = [x for x in story if x] \n",
    "                                             \n",
    "            ret.append((data_story,q,a)) #Nos données d'apprentissages\n",
    "            story.append('')\n",
    "        \n",
    "        else: \n",
    "            #Alors la phrase est tout simplement un des élements de raisonnement et non une question\n",
    "            story.append(tokenize(phrase))\n",
    "            \n",
    "    return ret\n",
    "\n",
    "def readAndParse(f):\n",
    "    data = parserBabi(f.readlines())\n",
    "    return [([substory for substories in story for substory in substories], q , a) for story,q,a in data]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Récupération des données\n",
    "\n",
    "On récupère les fichiers sur internet directement avec la fonction get_file, cette fonction a l'avantage de ne pas tout retelecharger si les données sont déjà sur la machines (dans ~/.keras/datasets). Puis on applique les fonctions du parser afin de récupérer les données dans la structure que l'on veut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 5500 samples , Test: 2200 samples , Validation: 2200 samples\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.data_utils import get_file\n",
    "import tarfile\n",
    "from random import shuffle\n",
    "\n",
    "try:\n",
    "    path = get_file('babi-tasks-v1-2.tar.gz', origin='http://www.thespermwhale.com/jaseweston/babi/tasks_1-20_v1-2.tar.gz')\n",
    "except:\n",
    "   print(\"erreur pendant le telechargement\")\n",
    "\n",
    "def trunc(f):\n",
    "    s = '{}'.format(f)\n",
    "    i, p, d = s.partition('.')\n",
    "    return int('.'.join([i, d][:1]))\n",
    "\n",
    "def splitData(data,split_take):\n",
    "    \n",
    "    size=len(data)\n",
    "    \n",
    "    train_prop,test_prop,val_prop = trunc(split_take[0] * size),trunc(split_take[1] * size), trunc(split_take[2] * size)\n",
    "    \n",
    "    return data[0:train_prop],data[train_prop:train_prop+test_prop],data[train_prop+test_prop:train_prop+test_prop+val_prop]\n",
    "        \n",
    "\n",
    "tar = tarfile.open(path)\n",
    "challenge = 'tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_{}.txt'\n",
    "#challenge = 'tasks_1-20_v1-2/en/qa19_path-finding_{}.txt'\n",
    "\n",
    "train = readAndParse(tar.extractfile(challenge.format('train')))\n",
    "test = readAndParse(tar.extractfile(challenge.format('test')))\n",
    "data = train+test\n",
    "\n",
    "proportions=(0.5,0.2,0.2) \n",
    "train,test,validation=splitData(data,proportions)\n",
    "\n",
    "vocab = sorted(reduce(lambda x, y: x | y, (set(story + q + [answer]) for story, q, answer in train + test + validation)))\n",
    "vocab_size = len(vocab) + 1\n",
    "word_idx = dict(((w,i+1) for i,w in enumerate(vocab)))\n",
    "\n",
    "story_max = max((len(x) for x,_,_ in train+test+validation))\n",
    "question_max = max((len(x) for _,x,_ in train+test+validation))\n",
    "\n",
    "print \"Training: {} samples , Test: {} samples , Validation: {} samples\".format(len(train),len(test),len(validation))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorisation\n",
    "\n",
    "Comme vu en cours on doit vectoriser nos données (les assimiler a des nombres et les mettre dans des matrices) afin de pouvoir entrainer notre réseau neuronal.\n",
    "\n",
    "La fonction pad_sequences plus bas permet de transformer notre liste de liste en matrice numpy en ajoutant des 0. pour complèter quand il n'y a pas de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Mettons tout ça dans des matrices\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "def vectorize(data,wordidx,storymaxlen,questionmaxlen):\n",
    "    X,Xq,Y = list(),list(),list()\n",
    "    \n",
    "    lookup = lambda m : wordidx[m]\n",
    "    \n",
    "    for story, question, reponse in data:\n",
    "        X.append(map(lookup,story))\n",
    "        Xq.append(map(lookup,question))\n",
    "        Yline = np.zeros(vocab_size)\n",
    "        Yline[wordidx[reponse]] = 1\n",
    "        Y.append(Yline)\n",
    "        \n",
    "    return pad_sequences(X, maxlen=story_max), pad_sequences(Xq, maxlen=question_max), np.array(Y)\n",
    "        \n",
    "    \n",
    "X,Xq,Y = vectorize(train,word_idx,story_max,question_max)\n",
    "X_test,Xq_test,Y_test = vectorize(test,word_idx,story_max,question_max)\n",
    "X_val,Xq_val,Y_val = vectorize(validation,word_idx,story_max,question_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  7 18 21 20 11  1  6 23 21 20 14  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  7 18 21 20 11  1  6 23\n",
      "  21 20 14  1  5 23 10 21 20 14  1  8 18 21 20 13  1]\n",
      " [ 0  0  0  0  7 18 21 20 11  1  6 23 21 20 14  1  5 23 10 21 20 14  1  8\n",
      "  18 21 20 13  1  6 18 21 20 19  1  8 16 21 20 11  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  8 22 21 20 19  1  8 23 21 20 11  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  8 22 21 20 19  1  8\n",
      "  23 21 20 11  1  7 23 21 20 12  1  5 18 21 20 14  1]\n",
      " [ 0  0  0  0  0  8 22 21 20 19  1  8 23 21 20 11  1  7 23 21 20 12  1  5\n",
      "  18 21 20 14  1  6 23 21 20 13  1  6 22 21 20 19  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[ 0  9 15  7  4]\n",
      " [ 0  9 15  5  4]\n",
      " [ 0  9 15  5  4]\n",
      " [ 2  9 15  5  4]\n",
      " [ 3  9 15  8  4]\n",
      " [ 0  9 15  8  4]\n",
      " [ 0  9 15  8  4]\n",
      " [ 0  9 15  8  4]\n",
      " [ 2  9 15  6  4]\n",
      " [ 3  9 15  5  4]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print X[0:10]\n",
    "print Xq[0:10]\n",
    "print Y[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle\n",
    "\n",
    "Ensuite nous crééons notre modèle keras, nous avions choisi donc de faire un modèle pour les story et pour les questions afin de pouvoir raisonner sur chacun d'eux différement puis de les combiner en un modèle, ainsi nous avons un seul modèle mais qui traite différement les story des questions. On a un LSTM dans le modèle des story car il faut raisonner d'abord sur les story seules puis les story avec les questions (raisonner sur les questions seule ne veut pas dire grand chose)\n",
    "\n",
    "Schema modèle:\n",
    "\n",
    "                    story_model                              question_model\n",
    "                         |                                           |\n",
    "                      Embedding                                  Embedding\n",
    "                          |                                          |\n",
    "                                                                    /\n",
    "                        LSTM                                       /\n",
    "                          |                                       /\n",
    "                        RepeatVector                            /\n",
    "                                    \\                          /\n",
    "                                      \\_______________________/\n",
    "                                                   |\n",
    "                                                   |\n",
    "                                              Merge(mode=sum)\n",
    "                                                   |\n",
    "                                                 LSTM\n",
    "                                                   |\n",
    "                                                 SoftMax\n",
    "\n",
    "Notes:\n",
    "\n",
    "- Avec un batchsize de 32 un nombre de 60 epochs semble optimal.\n",
    "- Le fait d'avoir utilisé un batchsize petit a amelioré les résultats (32 optimal?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plotLearningCurves_acc(history_model):\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('Precision du modele')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "def plotLearningCurves_loss(history_model):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Perte sur le modele')\n",
    "    plt.ylabel('Perte')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5500 samples, validate on 2200 samples\n",
      "Epoch 1/60\n",
      "5500/5500 [==============================] - 29s - loss: 1.9145 - acc: 0.1905 - val_loss: 1.6503 - val_acc: 0.3750\n",
      "Epoch 2/60\n",
      "5500/5500 [==============================] - 29s - loss: 1.5888 - acc: 0.3978 - val_loss: 1.4992 - val_acc: 0.4245\n",
      "Epoch 3/60\n",
      "5500/5500 [==============================] - 29s - loss: 1.4383 - acc: 0.3940 - val_loss: 1.4192 - val_acc: 0.3823\n",
      "Epoch 4/60\n",
      "5500/5500 [==============================] - 29s - loss: 1.3454 - acc: 0.4109 - val_loss: 1.3465 - val_acc: 0.4114\n",
      "Epoch 5/60\n",
      "5500/5500 [==============================] - 29s - loss: 1.3096 - acc: 0.4038 - val_loss: 1.3204 - val_acc: 0.3941\n",
      "Epoch 6/60\n",
      "5500/5500 [==============================] - 29s - loss: 1.2909 - acc: 0.4095 - val_loss: 1.3195 - val_acc: 0.3991\n",
      "Epoch 7/60\n",
      "5500/5500 [==============================] - 29s - loss: 1.2794 - acc: 0.4087 - val_loss: 1.3232 - val_acc: 0.4000\n",
      "Epoch 8/60\n",
      "5500/5500 [==============================] - 29s - loss: 1.2556 - acc: 0.4229 - val_loss: 1.3085 - val_acc: 0.3991\n",
      "Epoch 9/60\n",
      "5500/5500 [==============================] - 30s - loss: 1.2209 - acc: 0.4371 - val_loss: 1.2781 - val_acc: 0.4136\n",
      "Epoch 10/60\n",
      "5500/5500 [==============================] - 29s - loss: 1.1267 - acc: 0.5073 - val_loss: 1.1161 - val_acc: 0.5086\n",
      "Epoch 11/60\n",
      "5500/5500 [==============================] - 29s - loss: 0.9899 - acc: 0.5664 - val_loss: 0.9842 - val_acc: 0.5555\n",
      "Epoch 12/60\n",
      "5500/5500 [==============================] - 30s - loss: 0.9129 - acc: 0.5916 - val_loss: 0.9256 - val_acc: 0.6055\n",
      "Epoch 13/60\n",
      "5500/5500 [==============================] - 29s - loss: 0.8708 - acc: 0.6087 - val_loss: 0.8447 - val_acc: 0.6095\n",
      "Epoch 14/60\n",
      "5500/5500 [==============================] - 30s - loss: 0.7952 - acc: 0.6385 - val_loss: 0.7411 - val_acc: 0.6509\n",
      "Epoch 15/60\n",
      "5500/5500 [==============================] - 29s - loss: 0.7326 - acc: 0.6620 - val_loss: 0.7195 - val_acc: 0.6677\n",
      "Epoch 16/60\n",
      "5500/5500 [==============================] - 29s - loss: 0.7190 - acc: 0.6658 - val_loss: 0.7175 - val_acc: 0.6655\n",
      "Epoch 17/60\n",
      "5500/5500 [==============================] - 29s - loss: 0.7180 - acc: 0.6691 - val_loss: 0.7169 - val_acc: 0.6791\n",
      "Epoch 18/60\n",
      "5500/5500 [==============================] - 29s - loss: 0.7241 - acc: 0.6664 - val_loss: 0.7279 - val_acc: 0.6627\n",
      "Epoch 19/60\n",
      "5500/5500 [==============================] - 29s - loss: 0.7176 - acc: 0.6711 - val_loss: 0.7162 - val_acc: 0.6791\n",
      "Epoch 20/60\n",
      "5500/5500 [==============================] - 30s - loss: 0.7181 - acc: 0.6665 - val_loss: 0.7174 - val_acc: 0.6623\n",
      "Epoch 21/60\n",
      "5500/5500 [==============================] - 31s - loss: 0.7172 - acc: 0.6691 - val_loss: 0.7172 - val_acc: 0.6655\n",
      "Epoch 22/60\n",
      "5500/5500 [==============================] - 30s - loss: 0.7170 - acc: 0.6693 - val_loss: 0.7168 - val_acc: 0.6791\n",
      "Epoch 23/60\n",
      "5500/5500 [==============================] - 31s - loss: 0.7576 - acc: 0.6624 - val_loss: 0.7176 - val_acc: 0.6641\n",
      "Epoch 24/60\n",
      "5500/5500 [==============================] - 30s - loss: 0.7169 - acc: 0.6729 - val_loss: 0.7174 - val_acc: 0.6668\n",
      "Epoch 25/60\n",
      "5500/5500 [==============================] - 30s - loss: 0.7168 - acc: 0.6700 - val_loss: 0.7183 - val_acc: 0.6668\n",
      "Epoch 26/60\n",
      "5500/5500 [==============================] - 30s - loss: 0.7168 - acc: 0.6735 - val_loss: 0.7166 - val_acc: 0.6645\n",
      "Epoch 27/60\n",
      "5500/5500 [==============================] - 30s - loss: 0.7167 - acc: 0.6711 - val_loss: 0.7164 - val_acc: 0.6645\n",
      "Epoch 28/60\n",
      "5500/5500 [==============================] - 30s - loss: 0.7171 - acc: 0.6695 - val_loss: 0.7167 - val_acc: 0.6600\n",
      "Epoch 29/60\n",
      "5500/5500 [==============================] - 29s - loss: 0.7168 - acc: 0.6722 - val_loss: 0.7168 - val_acc: 0.6705\n",
      "Epoch 30/60\n",
      "5500/5500 [==============================] - 30s - loss: 0.7163 - acc: 0.6716 - val_loss: 0.7180 - val_acc: 0.6591\n",
      "Epoch 31/60\n",
      "5500/5500 [==============================] - 29s - loss: 0.7176 - acc: 0.6733 - val_loss: 0.7154 - val_acc: 0.6850\n",
      "Epoch 32/60\n",
      "5500/5500 [==============================] - 30s - loss: 0.7478 - acc: 0.6685 - val_loss: 0.7307 - val_acc: 0.6668\n",
      "Epoch 33/60\n",
      "5500/5500 [==============================] - 29s - loss: 0.7187 - acc: 0.6731 - val_loss: 0.7172 - val_acc: 0.6700\n",
      "Epoch 34/60\n",
      "5500/5500 [==============================] - 30s - loss: 0.7164 - acc: 0.6727 - val_loss: 0.7172 - val_acc: 0.6532\n",
      "Epoch 35/60\n",
      "5500/5500 [==============================] - 30s - loss: 0.7166 - acc: 0.6740 - val_loss: 0.7163 - val_acc: 0.6705\n",
      "Epoch 36/60\n",
      "5500/5500 [==============================] - 29s - loss: 0.7334 - acc: 0.6696 - val_loss: 0.7159 - val_acc: 0.6705\n",
      "Epoch 37/60\n",
      "5500/5500 [==============================] - 31s - loss: 0.7160 - acc: 0.6709 - val_loss: 0.7155 - val_acc: 0.6659\n",
      "Epoch 38/60\n",
      "5500/5500 [==============================] - 30s - loss: 0.7160 - acc: 0.6733 - val_loss: 0.7158 - val_acc: 0.6682\n",
      "Epoch 39/60\n",
      "5500/5500 [==============================] - 31s - loss: 0.7163 - acc: 0.6720 - val_loss: 0.7155 - val_acc: 0.6705\n",
      "Epoch 40/60\n",
      "5500/5500 [==============================] - 31s - loss: 0.7164 - acc: 0.6715 - val_loss: 0.7156 - val_acc: 0.6645\n",
      "Epoch 41/60\n",
      "5500/5500 [==============================] - 30s - loss: 0.7164 - acc: 0.6707 - val_loss: 0.7147 - val_acc: 0.6686\n",
      "Epoch 42/60\n",
      "5500/5500 [==============================] - 30s - loss: 0.7209 - acc: 0.6725 - val_loss: 0.7188 - val_acc: 0.6691\n",
      "Epoch 43/60\n",
      "5500/5500 [==============================] - 30s - loss: 0.7162 - acc: 0.6736 - val_loss: 0.7150 - val_acc: 0.6682\n",
      "Epoch 44/60\n",
      "5500/5500 [==============================] - 30s - loss: 0.7167 - acc: 0.6736 - val_loss: 0.7147 - val_acc: 0.6645\n",
      "Epoch 45/60\n",
      "5500/5500 [==============================] - 30s - loss: 0.7163 - acc: 0.6693 - val_loss: 0.7156 - val_acc: 0.6705\n",
      "Epoch 46/60\n",
      "5500/5500 [==============================] - 30s - loss: 0.7160 - acc: 0.6722 - val_loss: 0.7156 - val_acc: 0.6705\n",
      "Epoch 47/60\n",
      "5500/5500 [==============================] - 30s - loss: 0.7161 - acc: 0.6744 - val_loss: 0.7156 - val_acc: 0.6664\n",
      "Epoch 48/60\n",
      "5500/5500 [==============================] - 30s - loss: 0.7160 - acc: 0.6740 - val_loss: 0.7157 - val_acc: 0.6664\n",
      "Epoch 49/60\n",
      "5500/5500 [==============================] - 30s - loss: 0.7159 - acc: 0.6753 - val_loss: 0.7156 - val_acc: 0.6705\n",
      "Epoch 50/60\n",
      "5500/5500 [==============================] - 30s - loss: 0.7160 - acc: 0.6722 - val_loss: 0.7158 - val_acc: 0.6645\n",
      "Epoch 51/60\n",
      "5500/5500 [==============================] - 29s - loss: 0.7160 - acc: 0.6733 - val_loss: 0.7166 - val_acc: 0.6664\n",
      "Epoch 52/60\n",
      "5500/5500 [==============================] - 30s - loss: 0.7162 - acc: 0.6747 - val_loss: 0.7161 - val_acc: 0.6623\n",
      "Epoch 53/60\n",
      "5500/5500 [==============================] - 29s - loss: 0.7165 - acc: 0.6729 - val_loss: 0.7159 - val_acc: 0.6623\n",
      "Epoch 54/60\n",
      "5500/5500 [==============================] - 30s - loss: 0.7162 - acc: 0.6709 - val_loss: 0.7153 - val_acc: 0.6623\n",
      "Epoch 55/60\n",
      "5500/5500 [==============================] - 30s - loss: 0.7217 - acc: 0.6716 - val_loss: 0.7152 - val_acc: 0.6623\n",
      "Epoch 56/60\n",
      "5500/5500 [==============================] - 29s - loss: 0.7158 - acc: 0.6747 - val_loss: 0.7229 - val_acc: 0.6618\n",
      "Epoch 57/60\n",
      "5500/5500 [==============================] - 29s - loss: 0.7186 - acc: 0.6705 - val_loss: 0.7162 - val_acc: 0.6705\n",
      "Epoch 58/60\n",
      "5500/5500 [==============================] - 29s - loss: 0.7163 - acc: 0.6675 - val_loss: 0.7263 - val_acc: 0.6577\n",
      "Epoch 59/60\n",
      "5500/5500 [==============================] - 29s - loss: 0.7168 - acc: 0.6725 - val_loss: 0.7164 - val_acc: 0.6636\n",
      "Epoch 60/60\n",
      "5500/5500 [==============================] - 30s - loss: 0.7162 - acc: 0.6729 - val_loss: 0.7160 - val_acc: 0.6614\n"
     ]
    }
   ],
   "source": [
    "#Model\n",
    "\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Dense, Merge,RepeatVector,Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "\n",
    "\n",
    "embed_size = 50\n",
    "batch_size=128\n",
    "epochs=60\n",
    "\n",
    "story_model = Sequential()\n",
    "story_model.add(Embedding(vocab_size,embed_size,input_length=story_max))\n",
    "\n",
    "\n",
    "question_model = Sequential()\n",
    "question_model.add(Embedding(vocab_size,embed_size,input_length=question_max))\n",
    "question_model.add(LSTM(embed_size))\n",
    "question_model.add(RepeatVector(story_max)) #permet d'ajuster la taille du modèle afin de préparer un merge\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Merge([story_model, question_model], mode='concat'))\n",
    "model.add(LSTM(embed_size))\n",
    "model.add(Dense(vocab_size))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=RMSprop(lr=0.01),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history_lstm_question = model.fit([X, Xq], Y, batch_size=batch_size, nb_epoch=epochs,validation_data=([X_val,Xq_val],Y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2200/2200 [==============================] - 2s     \n",
      "\n",
      "Perte = 0.718\n",
      "Précision = 66%\n"
     ]
    }
   ],
   "source": [
    "#Calcul de précision sur l'ensemble de test\n",
    "\n",
    "loss,acc = model.evaluate([X_test,Xq_test],Y_test, batch_size=batch_size)\n",
    "print \"\\nPerte = {:.3f}\".format(loss)\n",
    "print \"Précision = {:.0f}%\".format(acc*100)\n",
    "\n",
    "plotLearningCurves_acc(history_lstm_question)\n",
    "plotLearningCurves_loss(history_lstm_question)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1100 samples, validate on 1100 samples\n",
      "Epoch 1/60\n",
      "1100/1100 [==============================] - 4s - loss: 1.9295 - acc: 0.2000 - val_loss: 1.7829 - val_acc: 0.1964\n",
      "Epoch 2/60\n",
      "1100/1100 [==============================] - 5s - loss: 1.6635 - acc: 0.3255 - val_loss: 1.6137 - val_acc: 0.3309\n",
      "Epoch 3/60\n",
      "1100/1100 [==============================] - 5s - loss: 1.5109 - acc: 0.4036 - val_loss: 1.5255 - val_acc: 0.4073\n",
      "Epoch 4/60\n",
      "1100/1100 [==============================] - 5s - loss: 1.4479 - acc: 0.4091 - val_loss: 1.4450 - val_acc: 0.4018\n",
      "Epoch 5/60\n",
      "1100/1100 [==============================] - 5s - loss: 1.3764 - acc: 0.4173 - val_loss: 1.3933 - val_acc: 0.4118\n",
      "Epoch 6/60\n",
      "1100/1100 [==============================] - 5s - loss: 1.3399 - acc: 0.4136 - val_loss: 1.4165 - val_acc: 0.3909\n",
      "Epoch 7/60\n",
      "1100/1100 [==============================] - 5s - loss: 1.2963 - acc: 0.4273 - val_loss: 1.3681 - val_acc: 0.4000\n",
      "Epoch 8/60\n",
      "1100/1100 [==============================] - 5s - loss: 1.2719 - acc: 0.4073 - val_loss: 1.3840 - val_acc: 0.3900\n",
      "Epoch 9/60\n",
      "1100/1100 [==============================] - 5s - loss: 1.2613 - acc: 0.4327 - val_loss: 1.3603 - val_acc: 0.4118\n",
      "Epoch 10/60\n",
      "1100/1100 [==============================] - 5s - loss: 1.2271 - acc: 0.4318 - val_loss: 1.4015 - val_acc: 0.3873\n",
      "Epoch 11/60\n",
      "1100/1100 [==============================] - 5s - loss: 1.2143 - acc: 0.4491 - val_loss: 1.3571 - val_acc: 0.3818\n",
      "Epoch 12/60\n",
      "1100/1100 [==============================] - 5s - loss: 1.1850 - acc: 0.4591 - val_loss: 1.4351 - val_acc: 0.3427\n",
      "Epoch 13/60\n",
      "1100/1100 [==============================] - 5s - loss: 1.1519 - acc: 0.4855 - val_loss: 1.4540 - val_acc: 0.3782\n",
      "Epoch 14/60\n",
      "1100/1100 [==============================] - 5s - loss: 1.1280 - acc: 0.4927 - val_loss: 1.4987 - val_acc: 0.3464\n",
      "Epoch 15/60\n",
      "1100/1100 [==============================] - 5s - loss: 1.1249 - acc: 0.4927 - val_loss: 1.4538 - val_acc: 0.3682\n",
      "Epoch 16/60\n",
      "1100/1100 [==============================] - 5s - loss: 1.0772 - acc: 0.5109 - val_loss: 1.4938 - val_acc: 0.3800\n",
      "Epoch 17/60\n",
      "1100/1100 [==============================] - 5s - loss: 1.0370 - acc: 0.5455 - val_loss: 1.5265 - val_acc: 0.3555\n",
      "Epoch 18/60\n",
      "1100/1100 [==============================] - 5s - loss: 1.0162 - acc: 0.5445 - val_loss: 1.5098 - val_acc: 0.3827\n",
      "Epoch 19/60\n",
      "1100/1100 [==============================] - 5s - loss: 0.9962 - acc: 0.5709 - val_loss: 1.6018 - val_acc: 0.3827\n",
      "Epoch 20/60\n",
      "1100/1100 [==============================] - 5s - loss: 0.9638 - acc: 0.5882 - val_loss: 1.5921 - val_acc: 0.3709\n",
      "Epoch 21/60\n",
      "1100/1100 [==============================] - 5s - loss: 0.9144 - acc: 0.6064 - val_loss: 1.6663 - val_acc: 0.3791\n",
      "Epoch 22/60\n",
      "1100/1100 [==============================] - 5s - loss: 0.9104 - acc: 0.6045 - val_loss: 1.7275 - val_acc: 0.3591\n",
      "Epoch 23/60\n",
      "1100/1100 [==============================] - 5s - loss: 0.8733 - acc: 0.6236 - val_loss: 1.6869 - val_acc: 0.3782\n",
      "Epoch 24/60\n",
      "1100/1100 [==============================] - 5s - loss: 0.8588 - acc: 0.6345 - val_loss: 1.7370 - val_acc: 0.3664\n",
      "Epoch 25/60\n",
      "1100/1100 [==============================] - 5s - loss: 0.8319 - acc: 0.6409 - val_loss: 1.8672 - val_acc: 0.3591\n",
      "Epoch 26/60\n",
      "1100/1100 [==============================] - 5s - loss: 0.8121 - acc: 0.6500 - val_loss: 1.7948 - val_acc: 0.3782\n",
      "Epoch 27/60\n",
      "1100/1100 [==============================] - 5s - loss: 0.8153 - acc: 0.6527 - val_loss: 1.8713 - val_acc: 0.3709\n",
      "Epoch 28/60\n",
      "1100/1100 [==============================] - 5s - loss: 0.7984 - acc: 0.6591 - val_loss: 1.9854 - val_acc: 0.3618\n",
      "Epoch 29/60\n",
      "1100/1100 [==============================] - 5s - loss: 0.7677 - acc: 0.6718 - val_loss: 2.0380 - val_acc: 0.3545\n",
      "Epoch 30/60\n",
      "1100/1100 [==============================] - 5s - loss: 0.7780 - acc: 0.6764 - val_loss: 2.0336 - val_acc: 0.3664\n",
      "Epoch 31/60\n",
      "1100/1100 [==============================] - 5s - loss: 0.7903 - acc: 0.6673 - val_loss: 2.0882 - val_acc: 0.3673\n",
      "Epoch 32/60\n",
      "1100/1100 [==============================] - 5s - loss: 0.7561 - acc: 0.6891 - val_loss: 2.1172 - val_acc: 0.3727\n",
      "Epoch 33/60\n",
      "1100/1100 [==============================] - 5s - loss: 0.7690 - acc: 0.6664 - val_loss: 2.1294 - val_acc: 0.3791\n",
      "Epoch 34/60\n",
      "1100/1100 [==============================] - 5s - loss: 0.7342 - acc: 0.7000 - val_loss: 2.2139 - val_acc: 0.3509\n",
      "Epoch 35/60\n",
      "1100/1100 [==============================] - 5s - loss: 0.7606 - acc: 0.6655 - val_loss: 2.0949 - val_acc: 0.3627\n",
      "Epoch 36/60\n",
      "1100/1100 [==============================] - 5s - loss: 0.7260 - acc: 0.6882 - val_loss: 2.2856 - val_acc: 0.3591\n",
      "Epoch 37/60\n",
      "1100/1100 [==============================] - 5s - loss: 0.7465 - acc: 0.6673 - val_loss: 2.2408 - val_acc: 0.3691\n",
      "Epoch 38/60\n",
      "1100/1100 [==============================] - 5s - loss: 0.7404 - acc: 0.6782 - val_loss: 2.2049 - val_acc: 0.3764\n",
      "Epoch 39/60\n",
      "1100/1100 [==============================] - 5s - loss: 0.7590 - acc: 0.6718 - val_loss: 2.2995 - val_acc: 0.3627\n",
      "Epoch 40/60\n",
      "1100/1100 [==============================] - 5s - loss: 0.7464 - acc: 0.6709 - val_loss: 2.2940 - val_acc: 0.3618\n",
      "Epoch 41/60\n",
      "1100/1100 [==============================] - 5s - loss: 0.7230 - acc: 0.6845 - val_loss: 2.4230 - val_acc: 0.3564\n",
      "Epoch 42/60\n",
      "1100/1100 [==============================] - 5s - loss: 0.7611 - acc: 0.6818 - val_loss: 2.3881 - val_acc: 0.3591\n",
      "Epoch 43/60\n",
      "1100/1100 [==============================] - 5s - loss: 0.7248 - acc: 0.6827 - val_loss: 2.4935 - val_acc: 0.3527\n",
      "Epoch 44/60\n",
      "1100/1100 [==============================] - 5s - loss: 0.7368 - acc: 0.6782 - val_loss: 2.4152 - val_acc: 0.3709\n",
      "Epoch 45/60\n",
      "1100/1100 [==============================] - 5s - loss: 0.7359 - acc: 0.6909 - val_loss: 2.4071 - val_acc: 0.3791\n",
      "Epoch 46/60\n",
      "1100/1100 [==============================] - 5s - loss: 0.7164 - acc: 0.6927 - val_loss: 2.4779 - val_acc: 0.3527\n",
      "Epoch 47/60\n",
      "1100/1100 [==============================] - 5s - loss: 0.7393 - acc: 0.6845 - val_loss: 2.4589 - val_acc: 0.3618\n",
      "Epoch 48/60\n",
      "1100/1100 [==============================] - 5s - loss: 0.7203 - acc: 0.6909 - val_loss: 2.4365 - val_acc: 0.3618\n",
      "Epoch 49/60\n",
      "1100/1100 [==============================] - 5s - loss: 0.7255 - acc: 0.6836 - val_loss: 2.5107 - val_acc: 0.3582\n",
      "Epoch 50/60\n",
      "1100/1100 [==============================] - 5s - loss: 0.7711 - acc: 0.6755 - val_loss: 2.5620 - val_acc: 0.3800\n",
      "Epoch 51/60\n",
      "1100/1100 [==============================] - 5s - loss: 0.7347 - acc: 0.7018 - val_loss: 2.4923 - val_acc: 0.3600\n",
      "Epoch 52/60\n",
      "1100/1100 [==============================] - 5s - loss: 0.7426 - acc: 0.6791 - val_loss: 2.5206 - val_acc: 0.3609\n",
      "Epoch 53/60\n",
      "1100/1100 [==============================] - 5s - loss: 0.7325 - acc: 0.6873 - val_loss: 2.4883 - val_acc: 0.3536\n",
      "Epoch 54/60\n",
      "1100/1100 [==============================] - 5s - loss: 0.7068 - acc: 0.6918 - val_loss: 2.5511 - val_acc: 0.3655\n",
      "Epoch 55/60\n",
      "1100/1100 [==============================] - 5s - loss: 0.7446 - acc: 0.6782 - val_loss: 2.5055 - val_acc: 0.3509\n",
      "Epoch 56/60\n",
      "1100/1100 [==============================] - 5s - loss: 0.7275 - acc: 0.6818 - val_loss: 2.5148 - val_acc: 0.3473\n",
      "Epoch 57/60\n",
      "1100/1100 [==============================] - 5s - loss: 0.7074 - acc: 0.6918 - val_loss: 2.5354 - val_acc: 0.3591\n",
      "Epoch 58/60\n",
      "1100/1100 [==============================] - 5s - loss: 0.7278 - acc: 0.6873 - val_loss: 2.5208 - val_acc: 0.3564\n",
      "Epoch 59/60\n",
      "1100/1100 [==============================] - 5s - loss: 0.7358 - acc: 0.6909 - val_loss: 2.5460 - val_acc: 0.3536\n",
      "Epoch 60/60\n",
      "1100/1100 [==============================] - 5s - loss: 0.7129 - acc: 0.6855 - val_loss: 2.5533 - val_acc: 0.3655\n"
     ]
    }
   ],
   "source": [
    "#Model LSTM Symétrique Simple\n",
    "\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Dense, Merge,RepeatVector,Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "\n",
    "embed_size = 50\n",
    "batch_size=32\n",
    "epochs=60\n",
    "\n",
    "story_model = Sequential()\n",
    "story_model.add(Embedding(vocab_size,embed_size,input_length=story_max))\n",
    "story_model.add(LSTM(embed_size))\n",
    "\n",
    "\n",
    "question_model = Sequential()\n",
    "question_model.add(Embedding(vocab_size,embed_size,input_length=question_max))\n",
    "question_model.add(LSTM(embed_size))\n",
    "#question_model.add(RepeatVector(story_max)) #permet d'ajuster la taille du modèle afin de préparer un merge\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Merge([story_model,question_model], mode='concat'))\n",
    "model.add(Dense(vocab_size))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=RMSprop(lr=0.01),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history_lstm_simple = model.fit([X, Xq], Y, batch_size=batch_size, nb_epoch=epochs,validation_data=([X_val,Xq_val],Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2200/2200 [==============================] - 2s     \n",
      "\n",
      "Perte = 0.718\n",
      "Précision = 66%\n"
     ]
    }
   ],
   "source": [
    "#Calcul de précision sur l'ensemble de test\n",
    "\n",
    "loss,acc = model.evaluate([X_test,Xq_test],Y_test, batch_size=batch_size)\n",
    "print \"\\nPerte = {:.3f}\".format(loss)\n",
    "print \"Précision = {:.0f}%\".format(acc*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1100 samples, validate on 1100 samples\n",
      "Epoch 1/60\n",
      "1100/1100 [==============================] - 10s - loss: 2.0929 - acc: 0.1718 - val_loss: 2.0393 - val_acc: 0.1855\n",
      "Epoch 2/60\n",
      "1100/1100 [==============================] - 10s - loss: 1.7404 - acc: 0.2945 - val_loss: 1.6690 - val_acc: 0.3873\n",
      "Epoch 3/60\n",
      "1100/1100 [==============================] - 10s - loss: 1.5497 - acc: 0.4064 - val_loss: 1.5211 - val_acc: 0.3864\n",
      "Epoch 4/60\n",
      "1100/1100 [==============================] - 10s - loss: 1.4805 - acc: 0.4000 - val_loss: 1.6240 - val_acc: 0.3445\n",
      "Epoch 5/60\n",
      "1100/1100 [==============================] - 10s - loss: 1.4371 - acc: 0.3936 - val_loss: 1.6960 - val_acc: 0.3318\n",
      "Epoch 6/60\n",
      "1100/1100 [==============================] - 10s - loss: 1.3869 - acc: 0.4055 - val_loss: 1.4610 - val_acc: 0.3609\n",
      "Epoch 7/60\n",
      "1100/1100 [==============================] - 10s - loss: 1.3556 - acc: 0.4155 - val_loss: 1.4614 - val_acc: 0.3564\n",
      "Epoch 8/60\n",
      "1100/1100 [==============================] - 10s - loss: 1.2962 - acc: 0.4418 - val_loss: 1.4776 - val_acc: 0.3700\n",
      "Epoch 9/60\n",
      "1100/1100 [==============================] - 10s - loss: 1.2976 - acc: 0.4227 - val_loss: 1.4203 - val_acc: 0.3964\n",
      "Epoch 10/60\n",
      "1100/1100 [==============================] - 9s - loss: 1.2528 - acc: 0.4500 - val_loss: 1.5083 - val_acc: 0.3545\n",
      "Epoch 11/60\n",
      "1100/1100 [==============================] - 10s - loss: 1.2286 - acc: 0.4509 - val_loss: 1.4308 - val_acc: 0.3918\n",
      "Epoch 12/60\n",
      "1100/1100 [==============================] - 9s - loss: 1.1880 - acc: 0.4700 - val_loss: 1.5325 - val_acc: 0.3645\n",
      "Epoch 13/60\n",
      "1100/1100 [==============================] - 9s - loss: 1.1506 - acc: 0.4845 - val_loss: 1.5099 - val_acc: 0.3773\n",
      "Epoch 14/60\n",
      "1100/1100 [==============================] - 9s - loss: 1.1226 - acc: 0.4909 - val_loss: 1.5391 - val_acc: 0.3782\n",
      "Epoch 15/60\n",
      "1100/1100 [==============================] - 10s - loss: 1.0819 - acc: 0.5227 - val_loss: 1.5729 - val_acc: 0.3964\n",
      "Epoch 16/60\n",
      "1100/1100 [==============================] - 9s - loss: 1.0406 - acc: 0.5445 - val_loss: 1.6907 - val_acc: 0.3655\n",
      "Epoch 17/60\n",
      "1100/1100 [==============================] - 9s - loss: 1.0033 - acc: 0.5509 - val_loss: 1.8096 - val_acc: 0.3936\n",
      "Epoch 18/60\n",
      "1100/1100 [==============================] - 10s - loss: 1.0021 - acc: 0.5509 - val_loss: 1.8313 - val_acc: 0.3564\n",
      "Epoch 19/60\n",
      "1100/1100 [==============================] - 10s - loss: 0.9345 - acc: 0.5882 - val_loss: 2.0087 - val_acc: 0.3573\n",
      "Epoch 20/60\n",
      "1100/1100 [==============================] - 9s - loss: 0.9254 - acc: 0.6000 - val_loss: 2.0257 - val_acc: 0.3773\n",
      "Epoch 21/60\n",
      "1100/1100 [==============================] - 9s - loss: 0.9017 - acc: 0.6018 - val_loss: 2.0460 - val_acc: 0.3636\n",
      "Epoch 22/60\n",
      "1100/1100 [==============================] - 9s - loss: 0.8760 - acc: 0.6091 - val_loss: 2.1323 - val_acc: 0.3745\n",
      "Epoch 23/60\n",
      "1100/1100 [==============================] - 9s - loss: 0.8511 - acc: 0.6236 - val_loss: 2.1588 - val_acc: 0.3645\n",
      "Epoch 24/60\n",
      "1100/1100 [==============================] - 9s - loss: 0.8368 - acc: 0.6373 - val_loss: 2.3036 - val_acc: 0.3673\n",
      "Epoch 25/60\n",
      "1100/1100 [==============================] - 9s - loss: 0.8108 - acc: 0.6482 - val_loss: 2.3164 - val_acc: 0.3800\n",
      "Epoch 26/60\n",
      "1100/1100 [==============================] - 9s - loss: 0.7892 - acc: 0.6673 - val_loss: 2.4396 - val_acc: 0.3718\n",
      "Epoch 27/60\n",
      "1100/1100 [==============================] - 9s - loss: 0.7927 - acc: 0.6627 - val_loss: 2.4962 - val_acc: 0.3527\n",
      "Epoch 28/60\n",
      "1100/1100 [==============================] - 10s - loss: 0.7873 - acc: 0.6664 - val_loss: 2.6526 - val_acc: 0.3755\n",
      "Epoch 29/60\n",
      "1100/1100 [==============================] - 9s - loss: 0.7957 - acc: 0.6555 - val_loss: 2.7892 - val_acc: 0.3600\n",
      "Epoch 30/60\n",
      "1100/1100 [==============================] - 10s - loss: 0.7756 - acc: 0.6600 - val_loss: 2.8128 - val_acc: 0.3373\n",
      "Epoch 31/60\n",
      "1100/1100 [==============================] - 10s - loss: 0.7728 - acc: 0.6655 - val_loss: 2.8136 - val_acc: 0.3636\n",
      "Epoch 32/60\n",
      "1100/1100 [==============================] - 10s - loss: 0.7624 - acc: 0.6564 - val_loss: 2.9677 - val_acc: 0.3491\n",
      "Epoch 33/60\n",
      "1100/1100 [==============================] - 10s - loss: 0.7950 - acc: 0.6555 - val_loss: 2.9137 - val_acc: 0.3664\n",
      "Epoch 34/60\n",
      "1100/1100 [==============================] - 10s - loss: 0.7674 - acc: 0.6636 - val_loss: 2.9654 - val_acc: 0.3573\n",
      "Epoch 35/60\n",
      "1100/1100 [==============================] - 10s - loss: 0.7656 - acc: 0.6609 - val_loss: 3.0649 - val_acc: 0.3318\n",
      "Epoch 36/60\n",
      "1100/1100 [==============================] - 10s - loss: 0.7620 - acc: 0.6600 - val_loss: 2.9826 - val_acc: 0.3464\n",
      "Epoch 37/60\n",
      "1100/1100 [==============================] - 10s - loss: 0.7956 - acc: 0.6573 - val_loss: 2.9631 - val_acc: 0.3736\n",
      "Epoch 38/60\n",
      "1100/1100 [==============================] - 10s - loss: 0.7989 - acc: 0.6555 - val_loss: 2.8984 - val_acc: 0.3627\n",
      "Epoch 39/60\n",
      "1100/1100 [==============================] - 9s - loss: 0.7851 - acc: 0.6509 - val_loss: 3.0236 - val_acc: 0.3536\n",
      "Epoch 40/60\n",
      "1100/1100 [==============================] - 9s - loss: 0.7562 - acc: 0.6800 - val_loss: 3.0277 - val_acc: 0.3536\n",
      "Epoch 41/60\n",
      "1100/1100 [==============================] - 10s - loss: 0.7479 - acc: 0.6764 - val_loss: 3.2919 - val_acc: 0.3427\n",
      "Epoch 42/60\n",
      "1100/1100 [==============================] - 10s - loss: 0.7452 - acc: 0.6809 - val_loss: 3.2987 - val_acc: 0.3491\n",
      "Epoch 43/60\n",
      "1100/1100 [==============================] - 10s - loss: 0.7440 - acc: 0.6800 - val_loss: 3.0915 - val_acc: 0.3682\n",
      "Epoch 44/60\n",
      "1100/1100 [==============================] - 10s - loss: 0.7219 - acc: 0.6664 - val_loss: 3.2377 - val_acc: 0.3527\n",
      "Epoch 45/60\n",
      "1100/1100 [==============================] - 10s - loss: 0.7328 - acc: 0.6773 - val_loss: 3.3542 - val_acc: 0.3609\n",
      "Epoch 46/60\n",
      "1100/1100 [==============================] - 9s - loss: 0.7428 - acc: 0.6709 - val_loss: 3.1223 - val_acc: 0.3645\n",
      "Epoch 47/60\n",
      "1100/1100 [==============================] - 10s - loss: 0.7874 - acc: 0.6664 - val_loss: 3.0931 - val_acc: 0.3700\n",
      "Epoch 48/60\n",
      "1100/1100 [==============================] - 9s - loss: 0.7311 - acc: 0.6764 - val_loss: 3.1875 - val_acc: 0.3536\n",
      "Epoch 49/60\n",
      "1100/1100 [==============================] - 10s - loss: 0.7531 - acc: 0.6736 - val_loss: 3.1423 - val_acc: 0.3600\n",
      "Epoch 50/60\n",
      "1100/1100 [==============================] - 10s - loss: 0.7785 - acc: 0.6636 - val_loss: 3.1740 - val_acc: 0.3627\n",
      "Epoch 51/60\n",
      "1100/1100 [==============================] - 10s - loss: 0.7289 - acc: 0.6845 - val_loss: 3.1690 - val_acc: 0.3500\n",
      "Epoch 52/60\n",
      "1100/1100 [==============================] - 10s - loss: 0.7368 - acc: 0.6809 - val_loss: 3.2358 - val_acc: 0.3709\n",
      "Epoch 53/60\n",
      "1100/1100 [==============================] - 10s - loss: 0.7852 - acc: 0.6664 - val_loss: 3.0768 - val_acc: 0.3600\n",
      "Epoch 54/60\n",
      "1100/1100 [==============================] - 10s - loss: 0.7680 - acc: 0.6673 - val_loss: 3.1198 - val_acc: 0.3700\n",
      "Epoch 55/60\n",
      "1100/1100 [==============================] - 10s - loss: 0.7364 - acc: 0.6718 - val_loss: 3.1284 - val_acc: 0.3673\n",
      "Epoch 56/60\n",
      "1100/1100 [==============================] - 10s - loss: 0.7161 - acc: 0.6845 - val_loss: 3.4105 - val_acc: 0.3582\n",
      "Epoch 57/60\n",
      "1100/1100 [==============================] - 10s - loss: 0.7470 - acc: 0.6736 - val_loss: 3.2825 - val_acc: 0.3536\n",
      "Epoch 58/60\n",
      "1100/1100 [==============================] - 10s - loss: 0.7808 - acc: 0.6636 - val_loss: 3.1343 - val_acc: 0.3673\n",
      "Epoch 59/60\n",
      "1100/1100 [==============================] - 10s - loss: 0.7496 - acc: 0.6691 - val_loss: 3.2742 - val_acc: 0.3509\n",
      "Epoch 60/60\n",
      "1100/1100 [==============================] - 10s - loss: 0.7510 - acc: 0.6655 - val_loss: 3.2947 - val_acc: 0.3636\n"
     ]
    }
   ],
   "source": [
    "#Model Bi-LSTM\n",
    "\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Dense, Merge,RepeatVector,Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "\n",
    "def makeBiLSTM(input_size,mode):\n",
    "    left = Sequential()\n",
    "    right = Sequential()\n",
    "    \n",
    "    backward=False\n",
    "    \n",
    "    for bimodel in [left,right]:\n",
    "        bimodel.add(Embedding(vocab_size,embed_size,input_length=input_size))\n",
    "        bimodel.add(LSTM(embed_size,go_backwards=backward))\n",
    "        backward=True\n",
    "    \n",
    "    resulting_model = Sequential()\n",
    "    resulting_model.add(Merge([left,right],mode=mode))\n",
    "    resulting_model.add(Dense(embed_size))\n",
    "    \n",
    "    return resulting_model\n",
    "\n",
    "\n",
    "embed_size = 50\n",
    "batch_size=32\n",
    "epochs=60\n",
    "\n",
    "story_model = makeBiLSTM(story_max,'concat')\n",
    "\n",
    "question_model = makeBiLSTM(question_max,'concat')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Merge([story_model,question_model], mode='concat'))\n",
    "model.add(Dense(vocab_size))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=RMSprop(lr=0.01),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history = model.fit([X,X,Xq, Xq], Y, batch_size=batch_size, nb_epoch=epochs,validation_data=([X_val,X_val,Xq_val,Xq_val],Y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100/1100 [==============================] - 2s     \n",
      "\n",
      "Perte = 3.236\n",
      "Précision = 36%\n"
     ]
    }
   ],
   "source": [
    "#Calcul de précision sur l'ensemble de test\n",
    "\n",
    "loss,acc = model.evaluate([X_test,X_test,Xq_test,Xq_test],Y_test, batch_size=batch_size)\n",
    "print \"\\nPerte = {:.3f}\".format(loss)\n",
    "print \"Précision = {:.0f}%\".format(acc*100)\n",
    "\n",
    "plotLearningCurves_acc(history)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Sauvegarde des calculs avec Pickle\n",
    "\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "sys.setrecursionlimit(50000)\n",
    "\n",
    "model_lstm_q_file = open('model_lstm_q.pck','wb')\n",
    "pickle.dump((model,history_lstm_question),model_lstm_q_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
