{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Projet: Facebook BaBi tasks\n",
    "Notebook de la semaine du 22/03\n",
    "Par Thierry Loesch et Bryce Tichit\n",
    "\n",
    "Comme demandé par notre tuteur, nous allons désormais essayer d'adapter les travaux fait jusqu'ici sur un autre projet sensiblement identique.\n",
    "\n",
    "-----------------------------------\n",
    "\n",
    "5.1  Notation automatique de réponses courtes à des questions\n",
    "\n",
    "Les données sont ici pour le téléchargement et leur description est dans cet article\n",
    "\n",
    "Lorsque l'on connait:\n",
    "\n",
    "    une question,\n",
    "    une réponse d'un étudiant,\n",
    "    la bonne réponse, \n",
    "\n",
    "comment prédire la note à donné à la réponse de l'étudiant. Il peut être aussi intéressant d'essayer d'apprendre à générer la réponse. \n",
    "\n",
    "--------------------------\n",
    "\n",
    "On cherchera en premier à prédire la note de l'étudiant, le réseau devra rendre un réel. Normaliser les notes (les mettre entre 0 et 1) et activation par Sigmoid (output entre 0 et 1) afin de prédire la note.\n",
    "\n",
    "\n",
    "TODO:\n",
    "\n",
    "- Parser données\n",
    "- Vectorisation\n",
    "- Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from keras.utils.data_utils import get_file\n",
    "import zipfile\n",
    "import string\n",
    "\n",
    "def tokenize(sent):\n",
    "    \n",
    "    def remPunctuation(sent):\n",
    "        return \"\".join(l for l in sent if l not in string.punctuation)\n",
    "        \n",
    "    return [x.strip() for x in re.split('(\\W+)?', remPunctuation(sent.lower())) if x.strip()]\n",
    "\n",
    "def parseData(questions,answers,student_answers=''):\n",
    "    \n",
    "    #questions_data = dict() #ce dictionnaire contiendra les tuples (question,answer) indexés par la clé \"numéro de question\"\n",
    "    \n",
    "    questions_data = dict()\n",
    "    \n",
    "    for line in questions.split('\\n'): #une ligne = une question\n",
    "        line = line.decode('utf-8').strip()\n",
    "        try:\n",
    "            index,question = line.split(' ',1)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        questions_data[index] = [question.replace('<STOP>',''),None]\n",
    "    \n",
    "    for line in answers.split('\\n'):\n",
    "        line = line.decode('utf-8').strip()\n",
    "        \n",
    "        try:\n",
    "            index,answer = line.split(' ',1)\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        questions_data[index][1] = answer.replace('<STOP>','')\n",
    "        \n",
    "    questions_data = {k: tuple(map(tokenize,v)) for k, v in questions_data.items()}\n",
    "    \n",
    "    stud_ans = dict()\n",
    "    \n",
    "    for line in student_answers.split('\\n'):\n",
    "        line = line.decode('utf-8')\n",
    "        try:\n",
    "            index,ans = line.split(' ',1)\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        answers=ans.split('<STOP>')\n",
    "        answers=[a for a in answers if a]\n",
    "            \n",
    "        if index in stud_ans:\n",
    "            stud_ans[index] += map(tokenize,answers)\n",
    "        else:\n",
    "            stud_ans[index] = map(tokenize,answers)\n",
    "    \n",
    "    return questions_data,stud_ans\n",
    "        \n",
    "    \n",
    "def parseIntoExamples(qd,sa):\n",
    "    \n",
    "    ret = list()\n",
    "    \n",
    "    for index,q_a in qd.items():\n",
    "        for stud_ans in sa[index]:\n",
    "            ret.append((q_a[0],q_a[1],stud_ans))\n",
    "    return ret\n",
    "                       \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'0',\n",
       " u'000000',\n",
       " u'012',\n",
       " u'0x',\n",
       " u'1',\n",
       " u'10',\n",
       " u'100',\n",
       " u'115',\n",
       " u'123',\n",
       " u'12345',\n",
       " u'123456789',\n",
       " u'12345678910',\n",
       " u'124',\n",
       " u'154',\n",
       " u'18',\n",
       " u'1each',\n",
       " u'1existing',\n",
       " u'1initializing',\n",
       " u'1long',\n",
       " u'1specification',\n",
       " u'1st',\n",
       " u'2',\n",
       " u'20',\n",
       " u'256',\n",
       " u'2design',\n",
       " u'2n1',\n",
       " u'2nd',\n",
       " u'2program',\n",
       " u'2specifying',\n",
       " u'2the',\n",
       " u'3',\n",
       " u'32',\n",
       " u'35',\n",
       " u'3n',\n",
       " u'3risk',\n",
       " u'4',\n",
       " u'40',\n",
       " u'400',\n",
       " u'4verification',\n",
       " u'5',\n",
       " u'50',\n",
       " u'5555',\n",
       " u'5657',\n",
       " u'5coding',\n",
       " u'6',\n",
       " u'68',\n",
       " u'6testing',\n",
       " u'7',\n",
       " u'72',\n",
       " u'7refining',\n",
       " u'8',\n",
       " u'80',\n",
       " u'88123',\n",
       " u'8production',\n",
       " u'8th',\n",
       " u'9maintenance',\n",
       " u'a',\n",
       " u'abe',\n",
       " u'ability',\n",
       " u'able',\n",
       " u'about',\n",
       " u'above',\n",
       " u'abstract',\n",
       " u'abstraction',\n",
       " u'accepted',\n",
       " u'accepts',\n",
       " u'accesed',\n",
       " u'access',\n",
       " u'accessed',\n",
       " u'accessible',\n",
       " u'accessing',\n",
       " u'accessmodifier',\n",
       " u'accessspecifications',\n",
       " u'accessspecifiers',\n",
       " u'accomplish',\n",
       " u'accordance',\n",
       " u'according',\n",
       " u'accordingly',\n",
       " u'account',\n",
       " u'accurate',\n",
       " u'achieved',\n",
       " u'acknowledged',\n",
       " u'acordingly',\n",
       " u'across',\n",
       " u'act',\n",
       " u'acted',\n",
       " u'actions',\n",
       " u'activity',\n",
       " u'acts',\n",
       " u'actual',\n",
       " u'actually',\n",
       " u'ad',\n",
       " u'adapt',\n",
       " u'adaptors',\n",
       " u'add',\n",
       " u'added',\n",
       " u'adding',\n",
       " u'addition',\n",
       " u'additional',\n",
       " u'address',\n",
       " u'addressed',\n",
       " u'addresses',\n",
       " u'adds',\n",
       " u'adjacent',\n",
       " u'adjust',\n",
       " u'adjusted',\n",
       " u'adt',\n",
       " u'advance',\n",
       " u'advantage',\n",
       " u'advantages',\n",
       " u'advises',\n",
       " u'affect',\n",
       " u'affected',\n",
       " u'affecting',\n",
       " u'affects',\n",
       " u'after',\n",
       " u'again',\n",
       " u'against',\n",
       " u'agian',\n",
       " u'alarm',\n",
       " u'algorithm',\n",
       " u'algorithms',\n",
       " u'algorithyms',\n",
       " u'alias',\n",
       " u'all',\n",
       " u'allocate',\n",
       " u'allocated',\n",
       " u'allocating',\n",
       " u'allocation',\n",
       " u'allot',\n",
       " u'allow',\n",
       " u'allowed',\n",
       " u'allowing',\n",
       " u'allows',\n",
       " u'almost',\n",
       " u'along',\n",
       " u'already',\n",
       " u'also',\n",
       " u'alt',\n",
       " u'alter',\n",
       " u'altered',\n",
       " u'alternate',\n",
       " u'alternative',\n",
       " u'although',\n",
       " u'always',\n",
       " u'ammout',\n",
       " u'among',\n",
       " u'amonts',\n",
       " u'amount',\n",
       " u'amounts',\n",
       " u'amout',\n",
       " u'ampersand',\n",
       " u'an',\n",
       " u'ana',\n",
       " u'analogy',\n",
       " u'analysis',\n",
       " u'ancestor',\n",
       " u'ancestors',\n",
       " u'and',\n",
       " u'another',\n",
       " u'answer',\n",
       " u'answered',\n",
       " u'answers',\n",
       " u'anther',\n",
       " u'any',\n",
       " u'anything',\n",
       " u'anytime',\n",
       " u'anywhere',\n",
       " u'appear',\n",
       " u'application',\n",
       " u'applications',\n",
       " u'applied',\n",
       " u'applies',\n",
       " u'approach',\n",
       " u'appropriate',\n",
       " u'aptr',\n",
       " u'arangment',\n",
       " u'arbitrary',\n",
       " u'architecture',\n",
       " u'are',\n",
       " u'area',\n",
       " u'argument',\n",
       " u'arguments',\n",
       " u'arise',\n",
       " u'arithmetic',\n",
       " u'around',\n",
       " u'arranged',\n",
       " u'arrary',\n",
       " u'arrarys',\n",
       " u'array',\n",
       " u'arraybased',\n",
       " u'arraybases',\n",
       " u'arraylist',\n",
       " u'arrayname',\n",
       " u'arrayptr',\n",
       " u'arrays',\n",
       " u'arraysize',\n",
       " u'arriving',\n",
       " u'art',\n",
       " u'as',\n",
       " u'ask',\n",
       " u'asking',\n",
       " u'assessment',\n",
       " u'assign',\n",
       " u'assigned',\n",
       " u'assigning',\n",
       " u'assigns',\n",
       " u'associated',\n",
       " u'associative',\n",
       " u'assume',\n",
       " u'assuming',\n",
       " u'at',\n",
       " u'atleast',\n",
       " u'atributes',\n",
       " u'attach',\n",
       " u'attached',\n",
       " u'attaching',\n",
       " u'attatched',\n",
       " u'attempt',\n",
       " u'attempted',\n",
       " u'attribute',\n",
       " u'attributes',\n",
       " u'attrubutes',\n",
       " u'autocreate',\n",
       " u'automatic',\n",
       " u'automatically',\n",
       " u'available',\n",
       " u'avariable',\n",
       " u'average',\n",
       " u'avl',\n",
       " u'avoid',\n",
       " u'avoiding',\n",
       " u'away',\n",
       " u'awesome',\n",
       " u'b',\n",
       " u'back',\n",
       " u'backinto',\n",
       " u'backtrack',\n",
       " u'backup',\n",
       " u'backward',\n",
       " u'backwards',\n",
       " u'badly',\n",
       " u'balanced',\n",
       " u'band',\n",
       " u'bank',\n",
       " u'bas',\n",
       " u'base',\n",
       " u'based',\n",
       " u'bases',\n",
       " u'basic',\n",
       " u'basically',\n",
       " u'basics',\n",
       " u'basis',\n",
       " u'batter',\n",
       " u'be',\n",
       " u'because',\n",
       " u'become',\n",
       " u'becomes',\n",
       " u'becuase',\n",
       " u'been',\n",
       " u'bef',\n",
       " u'before',\n",
       " u'begin',\n",
       " u'beging',\n",
       " u'begining',\n",
       " u'beginning',\n",
       " u'begins',\n",
       " u'behavior',\n",
       " u'behaviors',\n",
       " u'behind',\n",
       " u'being',\n",
       " u'believe',\n",
       " u'belong',\n",
       " u'belonging',\n",
       " u'below',\n",
       " u'beneath',\n",
       " u'benefit',\n",
       " u'besides',\n",
       " u'best',\n",
       " u'bestcase',\n",
       " u'better',\n",
       " u'between',\n",
       " u'beyond',\n",
       " u'bidimensional',\n",
       " u'big',\n",
       " u'bigger',\n",
       " u'biggest',\n",
       " u'bigo',\n",
       " u'bigoh',\n",
       " u'bin',\n",
       " u'binary',\n",
       " u'bind',\n",
       " u'bit',\n",
       " u'bits',\n",
       " u'blah',\n",
       " u'block',\n",
       " u'blocks',\n",
       " u'bodies',\n",
       " u'body',\n",
       " u'book']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    path = get_file('shortAnswerGrading-v-2-0.zip',origin='http://web.eecs.umich.edu/~mihalcea/downloads/ShortAnswerGrading_v2.0.zip')\n",
    "except:\n",
    "    print \"error while downloading file\"\n",
    "    \n",
    "    \n",
    "archive = zipfile.ZipFile(path,'r')\n",
    "    \n",
    "questions = archive.read('data/sent/questions') \n",
    "answers = archive.read('data/sent/answers')\n",
    "student_answers = archive.read('data/sent/all') \n",
    "\n",
    "dic1,dic2 = parseData(questions,answers,student_answers)\n",
    "\n",
    "\n",
    "data = parseIntoExamples(dic1,dic2)\n",
    "\n",
    "#print data[0]\n",
    "\n",
    "vocab = set()\n",
    "for (_,__,x) in data:\n",
    "    #for x in el:\n",
    "    vocab.update(x)\n",
    "vocab=sorted(list(vocab))\n",
    "\n",
    "vocab[0:300]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A faire:\n",
    "- Nettoyer le vocabulaire pour diminuer sa taille, synonymes, lowercase\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
