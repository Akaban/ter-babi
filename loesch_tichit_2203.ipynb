{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Projet: Facebook BaBi tasks\n",
    "Notebook de la semaine du 22/03\n",
    "Par Thierry Loesch et Bryce Tichit\n",
    "\n",
    "Dernier notebook\n",
    "\n",
    "Comme demandé par notre tuteur, nous allons désormais essayer d'adapter les travaux fait jusqu'ici sur un autre projet sensiblement identique.\n",
    "\n",
    "-----------------------------------\n",
    "\n",
    "5.1  Notation automatique de réponses courtes à des questions\n",
    "\n",
    "Les données sont ici pour le téléchargement et leur description est dans cet article\n",
    "\n",
    "Lorsque l'on connait:\n",
    "\n",
    "    une question,\n",
    "    une réponse d'un étudiant,\n",
    "    la bonne réponse, \n",
    "\n",
    "comment prédire la note à donné à la réponse de l'étudiant. Il peut être aussi intéressant d'essayer d'apprendre à générer la réponse. \n",
    "\n",
    "--------------------------\n",
    "\n",
    "On cherchera en premier à prédire la note de l'étudiant, le réseau devra rendre un réel. Normaliser les notes (les mettre entre 0 et 1) et activation par Sigmoid (output entre 0 et 1) afin de prédire la note."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from keras.utils.data_utils import get_file\n",
    "import zipfile\n",
    "import string\n",
    "\n",
    "def tokenize(sent):\n",
    "    \n",
    "    def remPunctuation(sent):\n",
    "        return \"\".join(l for l in sent if l not in string.punctuation)\n",
    "        \n",
    "    return [x.strip() for x in re.split('(\\W+)?', remPunctuation(sent.lower())) if x.strip()]\n",
    "\n",
    "def parseData(questions,answers,student_answers=''):\n",
    "    \n",
    "    #questions_data = dict() #ce dictionnaire contiendra les tuples (question,answer) indexés par la clé \"numéro de question\"\n",
    "    \n",
    "    questions_data = dict()\n",
    "    \n",
    "    for line in questions.split('\\n'): #une ligne = une question\n",
    "        line = line.decode('utf-8').strip()\n",
    "        try:\n",
    "            index,question = line.split(' ',1)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        questions_data[index] = [question.replace('<STOP>',''),None]\n",
    "    \n",
    "    for line in answers.split('\\n'):\n",
    "        line = line.decode('utf-8').strip()\n",
    "        \n",
    "        try:\n",
    "            index,answer = line.split(' ',1)\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        questions_data[index][1] = answer.replace('<STOP>','')\n",
    "        \n",
    "    questions_data = {k: tuple(map(tokenize,v)) for k, v in questions_data.items()}\n",
    "    \n",
    "    stud_ans = dict()\n",
    "    \n",
    "    for line in student_answers.split('\\n'):\n",
    "        line = line.decode('utf-8')\n",
    "        try:\n",
    "            index,ans = line.split(' ',1)\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        answers=ans.split('<STOP>')\n",
    "        answers=[a for a in answers if a]\n",
    "            \n",
    "        if index in stud_ans:\n",
    "            stud_ans[index] += map(tokenize,answers)\n",
    "        else:\n",
    "            stud_ans[index] = map(tokenize,answers)\n",
    "    \n",
    "    return questions_data,stud_ans\n",
    "        \n",
    "    \n",
    "def parseIntoExamples(qd,sa):\n",
    "    \n",
    "    ret = list()\n",
    "    \n",
    "    for index,q_a in qd.items():\n",
    "        scores = [k for k in archive.read('data/scores/'+str(index+'/ave')).split('\\n') if k]\n",
    "        for stud_ans,score in zip(sa[index],scores):\n",
    "            ret.append((q_a[0],q_a[1],stud_ans,float(score)/5.))\n",
    "    return ret\n",
    "                       \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[u'0',\n",
       " u'000000',\n",
       " u'012',\n",
       " u'0x',\n",
       " u'1',\n",
       " u'10',\n",
       " u'115',\n",
       " u'12345',\n",
       " u'123456789',\n",
       " u'124',\n",
       " u'154',\n",
       " u'18',\n",
       " u'1each',\n",
       " u'1long',\n",
       " u'1st',\n",
       " u'2',\n",
       " u'20',\n",
       " u'256',\n",
       " u'2nd',\n",
       " u'2the',\n",
       " u'3',\n",
       " u'35',\n",
       " u'3n',\n",
       " u'4',\n",
       " u'40',\n",
       " u'400',\n",
       " u'5',\n",
       " u'5555',\n",
       " u'5657',\n",
       " u'6',\n",
       " u'68',\n",
       " u'7',\n",
       " u'72',\n",
       " u'8',\n",
       " u'80',\n",
       " u'88123',\n",
       " u'8th',\n",
       " u'a',\n",
       " u'ability',\n",
       " u'able',\n",
       " u'about',\n",
       " u'above',\n",
       " u'abstract',\n",
       " u'abstraction',\n",
       " u'accepted',\n",
       " u'accepts',\n",
       " u'accesed',\n",
       " u'access',\n",
       " u'accessed',\n",
       " u'accessible',\n",
       " u'accessing',\n",
       " u'accessmodifier',\n",
       " u'accessspecifications',\n",
       " u'accessspecifiers',\n",
       " u'accomplish',\n",
       " u'according',\n",
       " u'accordingly',\n",
       " u'account',\n",
       " u'accurate',\n",
       " u'achieved',\n",
       " u'acknowledged',\n",
       " u'acordingly',\n",
       " u'across',\n",
       " u'act',\n",
       " u'acted',\n",
       " u'actions',\n",
       " u'activity',\n",
       " u'actual',\n",
       " u'actually',\n",
       " u'ad',\n",
       " u'add',\n",
       " u'added',\n",
       " u'adding',\n",
       " u'addition',\n",
       " u'additional',\n",
       " u'address',\n",
       " u'addressed',\n",
       " u'addresses',\n",
       " u'adds',\n",
       " u'adjacent',\n",
       " u'adjust',\n",
       " u'adjusted',\n",
       " u'adt',\n",
       " u'advance',\n",
       " u'advantage',\n",
       " u'advantages',\n",
       " u'advises',\n",
       " u'affect',\n",
       " u'affected',\n",
       " u'affecting',\n",
       " u'affects',\n",
       " u'after',\n",
       " u'again',\n",
       " u'against',\n",
       " u'agian',\n",
       " u'algorithm',\n",
       " u'algorithms',\n",
       " u'algorithyms',\n",
       " u'alias',\n",
       " u'all',\n",
       " u'allocate',\n",
       " u'allocated',\n",
       " u'allocation',\n",
       " u'allot',\n",
       " u'allow',\n",
       " u'allowed',\n",
       " u'allowing',\n",
       " u'allows',\n",
       " u'almost',\n",
       " u'along',\n",
       " u'already',\n",
       " u'also',\n",
       " u'alter',\n",
       " u'altered',\n",
       " u'alternate',\n",
       " u'alternative',\n",
       " u'always',\n",
       " u'ammout',\n",
       " u'among',\n",
       " u'amonts',\n",
       " u'amount',\n",
       " u'amounts',\n",
       " u'amout',\n",
       " u'ampersand',\n",
       " u'an',\n",
       " u'ancestor',\n",
       " u'ancestors',\n",
       " u'and',\n",
       " u'another',\n",
       " u'answer',\n",
       " u'answered',\n",
       " u'answers',\n",
       " u'anther',\n",
       " u'any',\n",
       " u'anything',\n",
       " u'anytime',\n",
       " u'anywhere',\n",
       " u'appear',\n",
       " u'application',\n",
       " u'applications',\n",
       " u'applied',\n",
       " u'approach',\n",
       " u'appropriate',\n",
       " u'aptr',\n",
       " u'arangment',\n",
       " u'arbitrary',\n",
       " u'architecture',\n",
       " u'are',\n",
       " u'area',\n",
       " u'argument',\n",
       " u'arguments',\n",
       " u'around',\n",
       " u'arranged',\n",
       " u'array',\n",
       " u'arraybased',\n",
       " u'arrayname',\n",
       " u'arrayptr',\n",
       " u'arrays',\n",
       " u'arraysize',\n",
       " u'arriving',\n",
       " u'as',\n",
       " u'assessment',\n",
       " u'assigned',\n",
       " u'assigning',\n",
       " u'assigns',\n",
       " u'associated',\n",
       " u'assume',\n",
       " u'assuming',\n",
       " u'at',\n",
       " u'atleast',\n",
       " u'atributes',\n",
       " u'attach',\n",
       " u'attached',\n",
       " u'attaching',\n",
       " u'attatched',\n",
       " u'attempt',\n",
       " u'attribute',\n",
       " u'attributes',\n",
       " u'attrubutes',\n",
       " u'autocreate',\n",
       " u'automatic',\n",
       " u'automatically',\n",
       " u'available',\n",
       " u'avariable',\n",
       " u'average',\n",
       " u'avl',\n",
       " u'avoid',\n",
       " u'avoiding',\n",
       " u'avoids',\n",
       " u'away',\n",
       " u'awesome',\n",
       " u'b',\n",
       " u'back',\n",
       " u'backtrack',\n",
       " u'backup',\n",
       " u'backward',\n",
       " u'backwards',\n",
       " u'badly',\n",
       " u'balanced',\n",
       " u'bank',\n",
       " u'base',\n",
       " u'based',\n",
       " u'bases',\n",
       " u'basic',\n",
       " u'basically',\n",
       " u'basics',\n",
       " u'basis',\n",
       " u'be',\n",
       " u'because',\n",
       " u'become',\n",
       " u'becomes',\n",
       " u'been',\n",
       " u'before',\n",
       " u'begin',\n",
       " u'beging',\n",
       " u'begining',\n",
       " u'beginning',\n",
       " u'begins',\n",
       " u'behavior',\n",
       " u'behaviors',\n",
       " u'behaviour',\n",
       " u'behind',\n",
       " u'being',\n",
       " u'believe',\n",
       " u'belong',\n",
       " u'belonging',\n",
       " u'below',\n",
       " u'benefit',\n",
       " u'besides',\n",
       " u'best',\n",
       " u'bestcase',\n",
       " u'better',\n",
       " u'between',\n",
       " u'beyond',\n",
       " u'bidimensional',\n",
       " u'big',\n",
       " u'bigger',\n",
       " u'biggest',\n",
       " u'bigo',\n",
       " u'bigoh',\n",
       " u'bin',\n",
       " u'binary',\n",
       " u'bit',\n",
       " u'bits',\n",
       " u'blah',\n",
       " u'block',\n",
       " u'blocks',\n",
       " u'bodies',\n",
       " u'body',\n",
       " u'both',\n",
       " u'bothe',\n",
       " u'bottom',\n",
       " u'bounds',\n",
       " u'bpointer',\n",
       " u'bptr',\n",
       " u'brackets',\n",
       " u'brain',\n",
       " u'branch',\n",
       " u'branched',\n",
       " u'branches',\n",
       " u'branching',\n",
       " u'break',\n",
       " u'breaking',\n",
       " u'breaks',\n",
       " u'brief',\n",
       " u'briefly',\n",
       " u'brings',\n",
       " u'broken',\n",
       " u'bugs',\n",
       " u'build',\n",
       " u'building',\n",
       " u'built',\n",
       " u'burn',\n",
       " u'but',\n",
       " u'by',\n",
       " u'bydimensional',\n",
       " u'byte',\n",
       " u'bytes',\n",
       " u'c',\n",
       " u'calculate',\n",
       " u'calculations',\n",
       " u'call',\n",
       " u'called',\n",
       " u'caller',\n",
       " u'calling',\n",
       " u'calls',\n",
       " u'can',\n",
       " u'candidate',\n",
       " u'cannot',\n",
       " u'cant',\n",
       " u'capable',\n",
       " u'carry',\n",
       " u'case',\n",
       " u'case1',\n",
       " u'casen',\n",
       " u'cases',\n",
       " u'cast',\n",
       " u'cause',\n",
       " u'causes',\n",
       " u'causing']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    path = get_file('shortAnswerGrading-v-2-0.zip',origin='http://web.eecs.umich.edu/~mihalcea/downloads/ShortAnswerGrading_v2.0.zip')\n",
    "except:\n",
    "    print \"error while downloading file\"\n",
    "    \n",
    "    \n",
    "archive = zipfile.ZipFile(path,'r')\n",
    "    \n",
    "questions = archive.read('data/sent/questions') \n",
    "answers = archive.read('data/sent/answers')\n",
    "student_answers = archive.read('data/sent/all') \n",
    "\n",
    "dic1,dic2 = parseData(questions,answers,student_answers)\n",
    "\n",
    "\n",
    "data = parseIntoExamples(dic1,dic2)\n",
    "\n",
    "nbSamples = len(data)\n",
    "\n",
    "data_train = data[0:nbSamples/2]\n",
    "data_test = data[(nbSamples/2):-1]\n",
    "\n",
    "#print data[0]\n",
    "\n",
    "vocab = set()\n",
    "for (a,b,c,_) in data:\n",
    "    for x in [a,b,c]:\n",
    "        vocab.update(x)\n",
    "vocab=sorted(list(vocab))\n",
    "\n",
    "print len(vocab)\n",
    "\n",
    "vocab_size = len(vocab) +1\n",
    "word_idx = dict((c,i+1) for i,c in enumerate(vocab))\n",
    "question_maxsize = max((len(x) for x,_,_,_ in data))\n",
    "answer_stud_maxsize = max(len(x) for _,_,x,_ in data)\n",
    "answer_maxsize = max((len(x) for _,x,_,_ in data))\n",
    "\n",
    "vocab[0:300]\n",
    "\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A faire:\n",
    "- Nettoyer le vocabulaire pour diminuer sa taille, synonymes, lowercase\n",
    "\n",
    "Pour cela on peut utiliser NTLK et les Stemmer, afin de réduire significativement la taille du vocabulaire, également voir ce  qu'on peut faire pour les nombres. Les associer à un unique mot?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Mettons tout ça dans des matrices\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "#précision de 50% avec question , stud_answer , score\n",
    "\n",
    "def vectorize(data,wordidx,qmaxlen,amaxlen):\n",
    "    X,Xs,Y = list(),list(),list()\n",
    "    \n",
    "    lookup = lambda m : wordidx[m]\n",
    "    \n",
    "    for question, ans , student_answer, score in data:\n",
    "        X.append(map(lookup,ans))\n",
    "        Xs.append(map(lookup,student_answer))\n",
    "        Y.append(score)\n",
    "        \n",
    "    return pad_sequences(X, maxlen=qmaxlen), pad_sequences(Xs, maxlen=amaxlen), np.array(Y)\n",
    "        \n",
    "    \n",
    "X,Xq,Y = vectorize(data_train,word_idx,answer_maxsize,answer_stud_maxsize)\n",
    "X_test,Xq_test,Y_test = vectorize(data_test,word_idx,answer_maxsize,answer_stud_maxsize)\n",
    "#X_test,Xq_test,Y_test = vectorize(test,word_idx,story_max,question_max)\n",
    "#X_val,Xq_val,Y_val = vectorize(validation,word_idx,story_max,question_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0 2018   76 1333 2018 1162  949 1230 2181\n",
      "  2018  832  337 1695]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0 2018   76 1333 2018 1162  949 1230 2181\n",
      "  2018  832  337 1695]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0 2018   76 1333 2018 1162  949 1230 2181\n",
      "  2018  832  337 1695]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0 2018   76 1333 2018 1162  949 1230 2181\n",
      "  2018  832  337 1695]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0 2018   76 1333 2018 1162  949 1230 2181\n",
      "  2018  832  337 1695]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0 2018   76 1333 2018 1162  949 1230 2181\n",
      "  2018  832  337 1695]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0 2018   76 1333 2018 1162  949 1230 2181\n",
      "  2018  832  337 1695]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0 2018   76 1333 2018 1162  949 1230 2181\n",
      "  2018  832  337 1695]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0 2018   76 1333 2018 1162  949 1230 2181\n",
      "  2018  832  337 1695]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0 2018   76 1333 2018 1162  949 1230 2181\n",
      "  2018  832  337 1695]]\n",
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0   38 1464 2016 1468 2050 2018 1230   76 1333 2018  217 1411\n",
      "  1333   38  835 1509 1267 2018 1464 1468 2050 2018  832 1860 1048  287\n",
      "   208  283 2050  722]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0   38  832 1464 1040   38 1464 2016  423 2018   76 1333\n",
      "  2018  832  949 1230]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0  832 1466  148 1466  922  620 2136 2184 1462 2050 2018\n",
      "    76 1333   38  832]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0   38 1464 2050   38  832 1040 2018   76 2181 2018  337\n",
      "   811 2018  832 1695]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0 2029  287  208 1418 2050  835 1714  826  835 1933  949  158  128\n",
      "   163 2050 1380 1466]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0 1048  423 2018   76 1333\n",
      "  2018  832  949 1230]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0 2178 1048 1040  535   38  832 1464  286 1064  832 2197\n",
      "  2222 1368 1259  151]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0   38\n",
      "  1464 2050   38  832]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0   38 1464\n",
      "  2050   38  832 1065  423 2018   76 1333 2018  832  128  287  208 2120\n",
      "  2050  282 2016  832]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0  832 1466  148 1466  922  620 2136 2184 1462 2050 2018\n",
      "    76 1333   38  832]]\n",
      "[ 1.   1.   1.   1.   1.   0.7  0.7  1.   1.   1. ]\n"
     ]
    }
   ],
   "source": [
    "print X[0:10]\n",
    "print Xq[0:10]\n",
    "print Y[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modele\n",
    "\n",
    "Il s'agit du même modèle que pour les babi-tasks mais legèrement modifié, voir ce qu'on peut tenter comme modèle (question? answer? stud_answer?) mais à priori garder la même architecture.\n",
    "\n",
    "Actuellement les performances sont faibles à cause de la taille du vocabulaire (embed_size trop petit pour sa taille) il faut augmenter l'embed_size de manière raisonnable mais aussi diminuer la taille du vocabulaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_34 (Embedding)         (None, 53, 100)       222400                                       \n",
      "____________________________________________________________________________________________________\n",
      "lstm_26 (LSTM)                   (None, 100)           80400                                        \n",
      "____________________________________________________________________________________________________\n",
      "embedding_35 (Embedding)         (None, 74, 100)       222400                                       \n",
      "____________________________________________________________________________________________________\n",
      "lstm_27 (LSTM)                   (None, 100)           80400                                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 1)             201         merge_16[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 1)             0           dense_7[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 605801\n",
      "____________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "1221/1221 [==============================] - 41s - loss: 0.0806 - acc: 0.4447    \n",
      "Epoch 2/10\n",
      "1221/1221 [==============================] - 42s - loss: 0.0531 - acc: 0.4955    \n",
      "Epoch 3/10\n",
      "1221/1221 [==============================] - 46s - loss: 0.0453 - acc: 0.4955    \n",
      "Epoch 4/10\n",
      "1221/1221 [==============================] - 49s - loss: 0.0399 - acc: 0.4955    \n",
      "Epoch 5/10\n",
      "1221/1221 [==============================] - 49s - loss: 0.0347 - acc: 0.4980    \n",
      "Epoch 6/10\n",
      "1221/1221 [==============================] - 46s - loss: 0.0301 - acc: 0.4996    \n",
      "Epoch 7/10\n",
      "1221/1221 [==============================] - 46s - loss: 0.0271 - acc: 0.5012    \n",
      "Epoch 8/10\n",
      "1221/1221 [==============================] - 46s - loss: 0.0232 - acc: 0.5029    \n",
      "Epoch 9/10\n",
      "1221/1221 [==============================] - 47s - loss: 0.0218 - acc: 0.5045    \n",
      "Epoch 10/10\n",
      "1221/1221 [==============================] - 46s - loss: 0.0183 - acc: 0.5053    \n"
     ]
    }
   ],
   "source": [
    "#Model\n",
    "\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Dense, Merge,RepeatVector,Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "\n",
    "\n",
    "embed_size = 100\n",
    "batch_size=256\n",
    "epochs=10\n",
    "\n",
    "question_model = Sequential()\n",
    "question_model.add(Embedding(vocab_size,embed_size,input_length=answer_maxsize))\n",
    "question_model.add(LSTM(embed_size))\n",
    "\n",
    "ans_model = Sequential()\n",
    "ans_model.add(Embedding(vocab_size,embed_size,input_length=answer_stud_maxsize))\n",
    "ans_model.add(LSTM(embed_size))\n",
    "#ans_model.add(RepeatVector(answer_maxsize)) #permet d'ajuster la taille du modèle afin de préparer un merge\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Merge([question_model, ans_model], mode='concat',concat_axis=1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.01),loss='mse',metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = model.fit([X, Xq], Y, batch_size=batch_size, nb_epoch=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plotLearningCurves_acc(history_model,save=''):\n",
    "    plt.plot(history_model.history['acc'])\n",
    "    plt.plot(history_model.history['val_acc'])\n",
    "    plt.title('Precision du modele')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    if save:\n",
    "        plt.savefig(save,bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "def plotLearningCurves_loss(history_model,save=''):\n",
    "    plt.plot(history_model.history['loss'])\n",
    "    plt.plot(history_model.history['val_loss'])\n",
    "    plt.title('Perte sur le modele')\n",
    "    plt.ylabel('Perte')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    if save:\n",
    "        plt.savefig(save,bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1220/1220 [==============================] - 9s     \n",
      "\n",
      "Perte = 0.067\n",
      "Précision = 50%\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'val_acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-0f3b7b725595>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Précision = {:.0f}%\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mplotLearningCurves_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplotLearningCurves_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-0b2c926f7fee>\u001b[0m in \u001b[0;36mplotLearningCurves_acc\u001b[0;34m(history_model, save)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplotLearningCurves_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Precision du modele'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Precision'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val_acc'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGm1JREFUeJzt3X2QXfV93/H3RxLCSOJBEg8CCQmJRQaMsSyBEGA765La\naorRJEMTCNOQ2JO60wKJ3aEQu1NWZZqpmsSkM8TTcYudOHUsN7QOjItt2Q43aSUECyusIO1aT5GQ\nkCxg9WQhS1mtvv3jnF1dXd2rPbt7d8+9535eM3f2nrO/c+9XAn327Pf8zu8qIjAzs+KakHcBZmY2\nthz0ZmYF56A3Mys4B72ZWcE56M3MCs5Bb2ZWcJmCXtJyST2Stkh6rMr3H5T0tqSu9PHpsu99V9JB\nSc/Xs3AzM8tm0lADJE0AngbuAvYCnZKei4ieiqGrI+KRKi/xn4EpwGdHW6yZmQ1fljP6pcDWiNgV\nEX3AamBFlXGqdnBEvAgcHXmJZmY2GlmCfjawu2x7T7qv0q9Iel3S/5Q0py7VmZnZqGUJ+mpn6pXr\nJjwPXBMRi4AfAX822sLMzKw+huzRk5zBzy3bnkPSqx8UEQfLNv8bsGo4RUjygjtmZiMQEVXb5uWy\nnNF3Am2S5kmaDNxHcgY/SNKsss0VwOaK1xA1evhlxTbc44knnsi9BtfkmlqxLteU7ZHVkGf0EdEv\n6SFgDckPhmciolvSSqAzIr4DPCLpHqAPOAD85mDCS38LvB+YJulN4DMR8YPMFZqZ2ahkad0QEd8j\nCevyfU+UPf8C8IUax35sNAWamdno+M7Yc2hvb8+7hLO4pmxcU3aNWJdrqi8Np88zZkVI0Qh1mJk1\nE0lEnS7GmplZE3PQm5kVnIPezKzgHPRmZgXnoDczKzgHvZlZwTnozcwKzkFvZlZwmZZAMDOzsXPi\nBBw4MPxHVr4z1sysDiLg2LGRBXZfH8yYMbzH9OkwY0a2O2Md9GZmNfz857BjB2zbBm+9dTqYDx6s\nHtgTJw4/sGfMgKlTQUPG9dmyLoHgoDezlnb0KGzfnoR55eOdd+Caa6CtDebMgZkzq51Vn35+wQXj\nW7uD3swsdehQEtzVAv3wYbj22uTR1nbm4+qrk7P0RuWgN7OWEQG9vdXPyrdtSy52Vob4wOPKK2FC\nk84/dNCbWaFEwP79tcNcguuuq35mfvnlI+uBNzoHvZk1nVOnYO/e2mE+ZUrtM/MZM/Kufvw56M2s\nIZ08Cbt3Vw/yv/97uOSS6kF+7bVw8cV5V99YHPRmlpu+Pti5s3qY79oFV1xRPcwXLEimGlo2Dnoz\nG1PHj5+eYz7wGJjV8tZbMHt29TCfPx/e9768qy8GB72Zjdp779WeY/7226fnmJe3V9raYN48mDw5\n7+qLz0FvZpkcPlx7jvmhQ0k7pdqZeaPPMW8FdQ16ScuBPyZZ7fKZiFhV8f0HgT8A9qS7no6Ir5Z9\n74tAAP8xIr5e5fUd9GZjJCK5Pb/WTJbjx88+Ix94XHVV884xbwV1C3pJE4AtwF3AXqATuC8iesrG\nPAgsiYhHKo6dDrwKLAYEvAYsjojDFeMc9GajEJG0UmqFeUQyx7zaTJYrrijmHPNWkDXosyxTvBTY\nGhG70hdeDawAeirGVXuzTwJrBoJd0hpgOfCtDO9rZmXONcd8+/bkAmd5iN9995lzzB3mrStL0M8G\ndpdt7yEJ/0q/IumjJGf/n4uIt6ocO7DPzKro7689x3zHjrPnmP/qr3qOuQ0tS9BXOw+o7LM8D/xF\nRPRJ+izwdZJWT5ZjAejo6Bh83t7eTnt7e4bSzJrPUHPML7/8zDC/447Tc8ynTcu7estTqVSiVCoN\n+7gsPfplQEdELE+3Hwei8oJs2fgJQG9ETJd0H9AeEf8y/d5/BV6MiG9VHOMevRXK8ePJXZ7Vwrxy\njnn5BdD588d/qVtrXvW8GDsR+AnJGfo+4BXg/ojoLhszKyJ+mj7/ZeDRiLij4mLshPT5kog4VPEe\nDnprOu+9d/YNQwOP/fuTueSVFz6vu85zzK1+6nYxNiL6JT0ErOH09MpuSSuBzoj4DvCIpHuAPuAA\n8JvpsQclPUkS8AGsrAx5s0Z25EjtmSwHD545x3zRIrj33tNzzCf5E5mtQfiGKWt555pjfuxY9SmJ\nbW1J+8VzzC1PvjPWLBWRfCRcrTDv768+x7ytzXPMrbE56K3lRCSzWV55BV5//cw55pMn117HfOZM\nh7k1Jwe9Fd6770JnZxLsA4/zz4dbb4UPfxgWLjzdapk+Pe9qzerPQW+FcuwYdHWdGeq9vUmoL12a\nPG69Nembm7UKB701rZMnYfPmM0N9yxa46abTob50aXLG7ouh1soc9NYUyvvqA48NG5LpiQNn6UuX\nwoc+lLRlzOw0B701pHfeSfrq5b31886D2247faa+ZEmypouZnZuD3nJXq69+yy1ntmDcVzcbGQe9\njauTJ2HTpiTMB87W3Vc3G1sO+lFauRJ6Klfct7NEJIt0bdgAc+acGeruq5uNLQf9KBw7BpddBl/5\nis8+s7jssqQd47662fiq5ydMtZzOTvjgB+GBB/KuxMxs9Hy+WsW6dXDnnXlXYWZWHw76KtauddCb\nWXG4R1/h1Cm49NLkzsxZs/Kuxsystqw9ep/RV+jpSRbAcsibWVE46Cu4bWNmReOgr+ALsWZWNA76\nCj6jN7OicdCXefvtZNGtG2/MuxIzs/px0JdZtw6WLfPdsGZWLI60Mm7bmFkROejLOOjNrIgyBb2k\n5ZJ6JG2R9Ng5xt0r6ZSkxen2eZK+KmmjpA2SfqFehdfb8eOwcWOy6qKZWZEMuaiZpAnA08BdwF6g\nU9JzEdFTMW4a8DCwvmz3bwMRETdLugz4LnBLvYqvp9degxtugKlT867EzKy+spzRLwW2RsSuiOgD\nVgMrqox7ElgFnCjbdyPwI4CIeAc4JKkhg37tWrjjjryrMDOrvyxBPxvYXba9J903SNIiYE5EvFBx\n7I+BFZImSpoPLAGuHkW9Y8b9eTMrqizr0VdbMGdwBTJJAp4CHqxyzFeBG4BOYBewFjhZ7U06OjoG\nn7e3t9Pe3p6htPqISKZWfvnL4/aWZmbDViqVKJVKwz5uyNUrJS0DOiJiebr9OEnffVW6fRGwDThK\nEvCzgF7gnojoqnittcBnqvT3c129cssW+MQnYOfO3EowMxu2eq5e2Qm0SZonaTJwH/D8wDcj4khE\nXB4RCyJiPsnF2E9FRJekCyRNSQv6x0BfZcg3ArdtzKzIhmzdRES/pIeANSQ/GJ6JiG5JK4HOiPhO\n5SGcbt1cDnxfUj/wFvDP61d6/fhCrJkVmT94hGRa5Te/CYsW5VaCmdmwZW3dtHzQ9/bCggVw4ABM\nnJhLCWZmI+JPmMpo3Tq47TaHvJkVl4PeHzRiZgXX8kHvGTdmVnQt3aP/h3+AGTNg3z648MJxf3sz\ns1Fxjz6Dri647jqHvJkVW0sHvds2ZtYKHPQOejMruJYN+oGFzBz0ZlZ0LRv0O3bApElwdUMummxm\nVj8tG/QDbRsNeb3azKy5tXzQm5kVnYPezKzgWvKGqUOHYO7cZCGzSVk+Y8vMrAH5hqlzeOkluPVW\nh7yZtYaWDHp/0IiZtZKWDXr3582sVbRcj76vL1nIbM8euPjicXlLM7Mx4R59Da+/DvPnO+TNrHW0\nXNB72QMzazUtF/S+EGtmraalgj7CF2LNrPW0VNDv2gWnTiU9ejOzVpEp6CUtl9QjaYukx84x7l5J\npyQtTrcnSfpTSRslbZL0eL0KHwkvZGZmrWjIoJc0AXga+CTwAeB+SddXGTcNeBhYX7b7nwGTI+Jm\n4Bbgs5Lm1qPwkfCFWDNrRVnO6JcCWyNiV0T0AauBFVXGPQmsAk6U7QtgqqSJwJT0e0dGV/LIuT9v\nZq0oS9DPBnaXbe9J9w2StAiYExEvVBz7LHAM2AfsBP4wIg6NuNpROHIEtm2DRYvyeHczs/xkWdar\nWkd78DZWSQKeAh6sMm4pcBKYBcwE/q+kH0bEzsqBHR0dg8/b29tpb2/PUFp269fDkiUweXJdX9bM\nbNyUSiVKpdKwjxtyCQRJy4COiFiebj8ORESsSrcvArYBR0l+KMwCeoF7gE8DL0XEN9KxzwDfjYhn\nK95jzJdAeOKJZPmD3//9MX0bM7NxU88lEDqBNknzJE0G7gOeH/hmRByJiMsjYkFEzCe5GPupiOgC\n3gT+UVrQVGAZ0DP8P87ouT9vZq1qyKCPiH7gIWANsAlYHRHdklZKurvaIZxu9/wJcKGkN4CXgWci\n4o36lJ7dyZPwyitw++3j/c5mZvlridUrN2yABx6AzZvH7C3MzMadV68s47aNmbUyB72ZWcE56M3M\nCq7wQb97Nxw/Dm1teVdiZpaPwgf9wPo2XsjMzFpV4YPeHzRiZq2uJYLe/Xkza2WFnkd/9CjMmgW9\nvXD++XV/eTOzXHkePfDyy8lqlQ55M2tlhQ56f9CImVnBg94XYs3MCtyj7++HmTNh61a47LK6vrSZ\nWUNo+R79pk1wxRUOeTOzwga9p1WamSUc9GZmBVfYoPeMGzOzRCGDft8+OHwYFi7MuxIzs/wVMugH\nplVOKOSfzsxseAoZhe7Pm5md5qA3Myu4wt0wdexYMnf+3Xfhggvq8pJmZg2pZW+Y6uyED37QIW9m\nNqBwQe+2jZnZmTIFvaTlknokbZH02DnG3SvplKTF6favS9ogqSv92i/p5noVX42D3szsTEP26CVN\nALYAdwF7gU7gvojoqRg3Dfg/wHnAQxHRVfH9m4C/ioizPqa7Xj36U6fg0kuhuztZ58bMrMjq2aNf\nCmyNiF0R0QesBlZUGfcksAo4UeN17ge+meH9Rqy7G2bMcMibmZXLEvSzgd1l23vSfYMkLQLmRMQL\n53idX2OMg97LHpiZnW1ShjHVfi0Y7LNIEvAU8GCtYyQtBd6LiM213qSjo2PweXt7O+3t7RlKO5M/\naMTMiqxUKlEqlYZ9XJYe/TKgIyKWp9uPAxERq9Lti4BtwFGSgJ8F9AL3DPTpJX0JeDsi/lON96hL\nj/666+Db34abbhr1S5mZNbysPfosQT8R+AnJxdh9wCvA/RHRXWP8i8DnI2JDui3gTeCjEbGzxjGj\nDvr9++H666G312vcmFlrqNvF2IjoBx4C1gCbgNUR0S1ppaS7qx3Cma2bjwG7a4V8vaxbB7ff7pA3\nM6tUmCUQHn0ULrkEvvjFOhVlZtbgWm4JBF+INTOrrhBn9MePJzdK7d8PU6fWsTAzswbWUmf0r74K\nN9zgkDczq6YQQe/1bczManPQm5kVXNP36COSDxrZuBGuuqrOhZmZNbCW6dFv2QLTpjnkzcxqafqg\nd9vGzOzcHPRmZgXnoDczK7imvhj77rtw7bVw4ABMnDgGhZmZNbCWuBj70ktw220OeTOzc2nqoHfb\nxsxsaA56M7OCa9oe/YkTMHMm7NsHF144RoWZmTWwwvfou7pg4UKHvJnZUJo26Netc9vGzCyLpg16\nf9CImVk2Tdmjj4BZs6CzE+bOHcPCzMwaWKF79Nu3w+TJDnkzsyyaMug9rdLMLDsHvZlZwTVl0K9b\n5wuxZmZZZQp6Scsl9UjaIumxc4y7V9IpSYvL9t0saZ2kNyT9WNLk0RR88CC8+SZ86EOjeRUzs9Yx\naagBkiYATwN3AXuBTknPRURPxbhpwMPA+rJ9E4E/Bx6IiDckTQf6RlPwSy/BrbfCpCErNzMzyHZG\nvxTYGhG7IqIPWA2sqDLuSWAVcKJs3yeAH0fEGwARcXDEHw6bcn/ezGx4sgT9bGB32faedN8gSYuA\nORHxQsWxC9Pvf0/Sq5IeHU2x4KA3MxuuLA2QapPxB8/KJQl4CniwxuvfCdwCHAd+JOnViHixcmBH\nR8fg8/b2dtrb2896sb4+eO01WLYsQ9VmZgVTKpUolUrDPm7IO2MlLQM6ImJ5uv04EBGxKt2+CNgG\nHCX5oTAL6AXuAa4DPhkRn07H/jvg5xHxRxXvkamj09kJn/kMbNw4rD+jmVkh1fPO2E6gTdK8dMbM\nfcDzA9+MiCMRcXlELIiI+SQXYz8VEV3A94GbJb1P0iTgF4DNI/kDgds2ZmYjMWTQR0Q/8BCwBtgE\nrI6IbkkrJd1d7RDSdk9EHAK+BLwKdAGvRsR3R1qsg97MbPiaZlGzCJg9Own7+fPHqTAzswZWuEXN\ndu5Mvl5zTZ5VmJk1n6YJ+oFlDzTkzy4zMyvXNEHv/ryZ2cg46M3MCq4pLsYePgxz5sCBA3DeeeNY\nmJlZAyvUxdj162HJEoe8mdlINEXQr1vnto2Z2Ug1RdCvXesPGjEzG6mG79GfPAkzZiTz6GfMGN+6\nzMwaWWF69Bs3wtVXO+TNzEaq4YPe0yrNzEbHQW9mVnANH/QDSx+YmdnINHTQ794Nx49DW1velZiZ\nNa+GDvqBto0XMjMzG7mmCHozMxs5B72ZWcE17A1TR4/CrFnQ2wvnn59TYWZmDazpb5h6+WVYtMgh\nb2Y2Wg0b9G7bmJnVh4PezKzgGrJH39+frG2zfTtcemmOhZmZNbCm7tG/8QZceaVD3sysHjIFvaTl\nknokbZH02DnG3SvplKTF6fY8ScckdaWPL2d5Py97YGZWP5OGGiBpAvA0cBewF+iU9FxE9FSMmwY8\nDKyveIltEbF4OEWtXQsf//hwjjAzs1qynNEvBbZGxK6I6ANWAyuqjHsSWAWcqNg/7AUMfCHWzKx+\nsgT9bGB32faedN8gSYuAORHxQpXjr5H0mqQXJX1kqDfbuxd+9jN4//szVGZmZkMasnVD9TPywSky\nkgQ8BTxY5Zh9wNyIOJj27f9K0o0RcbTyBTs6OgDYtAkWLmxHas/0BzAzaxWlUolSqTTs44acXilp\nGdAREcvT7ceBiIhV6fZFwDbgKEnAzwJ6gXsioqvitV4E/k2V/YPTK3/3d5MZN4/VvORrZmZQ3+mV\nnUBbOoNmMnAf8PzANyPiSERcHhELImI+ycXYT0VEl6RL04u5SFoAtAE7zvVmnnFjZlZfQ7ZuIqJf\n0kPAGpIfDM9ERLeklUBnRHyn8hBOt24+BvwHSX1AP/DZiDhU672OHUtaN7fcMpI/ipmZVdNQd8aW\nSvB7vwcvvZR3RWZmja8p74z1tEozs/pz0JuZFVzDtG76+4OZM6GnB664Iu+KzMwaX9O1brq7YeZM\nh7yZWb01TNC7bWNmNjYc9GZmBeegNzMruIa5GHvJJUFvL0xomB89ZmaNrekuxt5+u0PezGwsNEy0\num1jZjY2HPRmZgXXMD36994LpkzJuxIzs+aRtUffMEHfCHWYmTWTprsYa2ZmY8NBb2ZWcA56M7OC\nc9CbmRWcg97MrOAc9GZmBeegNzMrOAe9mVnBOejNzAouU9BLWi6pR9IWSY+dY9y9kk5JWlyxf66k\nn0n6/GgLNjOz4Rky6CVNAJ4GPgl8ALhf0vVVxk0DHgbWV3mZLwEvjK7U8VcqlfIu4SyuKRvXlF0j\n1uWa6ivLGf1SYGtE7IqIPmA1sKLKuCeBVcCJ8p2SVgDbgU2jrHXcNeJ/WNeUjWvKrhHrck31lSXo\nZwO7y7b3pPsGSVoEzImIFyr2TwH+LbASGHLhHTMzq79JGcZUC+jBpSYlCXgKeLDKuJXAUxFxLBnm\nsDczG29DLlMsaRnQERHL0+3HgYiIVen2RcA24ChJkM8CeoF7gD8G5qQvNR3oB/59RHy54j28RrGZ\n2QjUZT16SROBnwB3AfuAV4D7I6K7xvgXgc9HxIaK/U8AP4uIL2Ur38zM6mHIHn1E9AMPAWtILqiu\njohuSSsl3V3tENyiMTNrGA3xCVNmZjZ2cr8zNuvNWONJ0jOS9kvamHctAJLmSPprSZsl/Z2kR/Ku\nCUDS+ZJelrQhreuJvGsaIGmCpC5Jz+ddC4CknZJ+nP5dvZJ3PQCSLpb0l5K6JW2SdFvO9SxM/366\n0q+HG+j/9c9JekPSRknfkDS5AWr6nfTf3dCZEBG5PUh+0GwD5gHnAa8D1+dZU1rXR4BFwMa8a0nr\nmQUsSp9PI7lmkvvfU1rPlPTrRJKb5ZbmXVNaz+eA/wE8n3ctaT07gOl511FR058Cv5U+nwRclHdN\nZbVNAPYCVzdALVel//0mp9vfAn4j55o+AGwEzk//7f0AuLbW+LzP6LPejDWuIuL/AQfzrmNARPw0\nIl5Pnx8Fuqm4lyEvEXEsfXo+SVjk3guUNAf4JeC/511LGdEAv0EPkHQh8NGI+BpARJyMiCM5l1Xu\nF4HtEbF7yJHjYyIwVdIkYArJD6E83QCsj4gTkVxH/Rvgl2sNzvt/vCFvxrIzSbqG5LeNl/OtJJG2\nSDYAPwV+EBGdeddEcl/HozTAD50yAXxfUqek3867GGAB8K6kr6Wtkq9IuiDvosr8GvDNvIsAiIi9\nwB8BbwJvAYci4of5VsUbwMckTU9vTP0l4Opag/MO+nPejGVnStcTehb4nfTMPncRcSoiPkxyv8Rt\nkm7Msx5J/xTYn/4GJBpnBtgdEXELyT/Ify3pIznXMwlYDPxJRCwGjgGP51tSQtJ5JPfh/GXetQBI\nuoSk0zCPpI0zTdKv51lTRPSQLDnzQ5J1xF4HTtYan3fQ7wHmlm3PIf9fiRpS+ivjs8CfR8RzeddT\nKf21vwQsz7mUO4F7JO0gOSP8uKSv51wTEfHT9Os7wLdJ2pZ52gPsjohX0+1nSYK/EfwT4LX076oR\n/CKwIyIOpG2S/w3ckXNNRMTXImJJRLSTtJq31hqbd9B3Am2S5qVXse8DGmKWBI11NgjwVWBzRPyX\nvAsZIOlSSRenzy8g+QfRk2dNEfGFiJgbEQtI/n/664j4jTxrkjQl/W0MSVOBT5D86p2biNgP7Ja0\nMN11F7A5x5LK3U+DtG1SbwLLJL0vXfLlLpLrZLmSdFn6dS5Jf77m31mWtW7GTET0Sxq4GWsC8EzU\nuON2PEn6C6AdmCnpTeCJgYtWOdVzJ/AA8HdpPzyAL0TE9/KqKXUl8GfpUtYTgG9FxcJ2BsAVwLfT\npT4mAd+IiDU51wTwCPCNtFWyA/itnOspP2H4F3nXMiAiXpH0LLAB6Eu/fiXfqgD4X5JmkNT0ryLi\ncK2BvmHKzKzg8m7dmJnZGHPQm5kVnIPezKzgHPRmZgXnoDczKzgHvZlZwTnozcwKzkFvZlZw/x/a\nC/ROVVEYJAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd15f097350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Calcul de précision sur l'ensemble de test\n",
    "\n",
    "loss,acc = model.evaluate([X_test,Xq_test],Y_test, batch_size=batch_size)\n",
    "print \"\\nPerte = {:.3f}\".format(loss)\n",
    "print \"Précision = {:.0f}%\".format(acc*100)\n",
    "\n",
    "plotLearningCurves_acc(history)\n",
    "\n",
    "plotLearningCurves_loss(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
