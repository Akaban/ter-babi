{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Projet: Facebook BaBi tasks\n",
    "Notebook de la semaine du 22/03\n",
    "Par Thierry Loesch et Bryce Tichit\n",
    "\n",
    "Comme demandé par notre tuteur, nous allons désormais essayer d'adapter les travaux fait jusqu'ici sur un autre projet sensiblement identique.\n",
    "\n",
    "-----------------------------------\n",
    "\n",
    "5.1  Notation automatique de réponses courtes à des questions\n",
    "\n",
    "Les données sont ici pour le téléchargement et leur description est dans cet article\n",
    "\n",
    "Lorsque l'on connait:\n",
    "\n",
    "    une question,\n",
    "    une réponse d'un étudiant,\n",
    "    la bonne réponse, \n",
    "\n",
    "comment prédire la note à donné à la réponse de l'étudiant. Il peut être aussi intéressant d'essayer d'apprendre à générer la réponse. \n",
    "\n",
    "--------------------------\n",
    "\n",
    "On cherchera en premier à prédire la note de l'étudiant, le réseau devra rendre un réel. Normaliser les notes (les mettre entre 0 et 1) et activation par Sigmoid (output entre 0 et 1) afin de prédire la note.\n",
    "\n",
    "\n",
    "TODO:\n",
    "\n",
    "- Parser données\n",
    "- Vectorisation\n",
    "- Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from keras.utils.data_utils import get_file\n",
    "import zipfile\n",
    "import string\n",
    "\n",
    "def tokenize(sent):\n",
    "    \n",
    "    def remPunctuation(sent):\n",
    "        return \"\".join(l for l in sent if l not in string.punctuation)\n",
    "        \n",
    "    return [x.strip() for x in re.split('(\\W+)?', remPunctuation(sent.lower())) if x.strip()]\n",
    "\n",
    "def parseData(questions,answers,student_answers=''):\n",
    "    \n",
    "    #questions_data = dict() #ce dictionnaire contiendra les tuples (question,answer) indexés par la clé \"numéro de question\"\n",
    "    \n",
    "    questions_data = dict()\n",
    "    \n",
    "    for line in questions.split('\\n'): #une ligne = une question\n",
    "        line = line.decode('utf-8').strip()\n",
    "        try:\n",
    "            index,question = line.split(' ',1)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        questions_data[index] = [question.replace('<STOP>',''),None]\n",
    "    \n",
    "    for line in answers.split('\\n'):\n",
    "        line = line.decode('utf-8').strip()\n",
    "        \n",
    "        try:\n",
    "            index,answer = line.split(' ',1)\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        questions_data[index][1] = answer.replace('<STOP>','')\n",
    "        \n",
    "    questions_data = {k: tuple(map(tokenize,v)) for k, v in questions_data.items()}\n",
    "    \n",
    "    stud_ans = dict()\n",
    "    \n",
    "    for line in student_answers.split('\\n'):\n",
    "        line = line.decode('utf-8')\n",
    "        try:\n",
    "            index,ans = line.split(' ',1)\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        answers=ans.split('<STOP>')\n",
    "        answers=[a for a in answers if a]\n",
    "            \n",
    "        if index in stud_ans:\n",
    "            stud_ans[index] += map(tokenize,answers)\n",
    "        else:\n",
    "            stud_ans[index] = map(tokenize,answers)\n",
    "    \n",
    "    return questions_data,stud_ans\n",
    "        \n",
    "    \n",
    "def parseIntoExamples(qd,sa):\n",
    "    \n",
    "    ret = list()\n",
    "    \n",
    "    for index,q_a in qd.items():\n",
    "        scores = [k for k in archive.read('data/scores/'+str(index+'/ave')).split('\\n') if k]\n",
    "        for stud_ans,score in zip(sa[index],scores):\n",
    "            try:\n",
    "                ret.append((q_a[0],q_a[1],stud_ans,float(score)/5.))\n",
    "            except:\n",
    "                print \"Erreur float.Score = {} \".format(score,stud_ans)\n",
    "    return ret\n",
    "                       \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[u'0',\n",
       " u'000000',\n",
       " u'012',\n",
       " u'0x',\n",
       " u'1',\n",
       " u'10',\n",
       " u'115',\n",
       " u'12345',\n",
       " u'123456789',\n",
       " u'124',\n",
       " u'154',\n",
       " u'18',\n",
       " u'1each',\n",
       " u'1long',\n",
       " u'1st',\n",
       " u'2',\n",
       " u'20',\n",
       " u'256',\n",
       " u'2nd',\n",
       " u'2the',\n",
       " u'3',\n",
       " u'35',\n",
       " u'3n',\n",
       " u'4',\n",
       " u'40',\n",
       " u'400',\n",
       " u'5',\n",
       " u'5555',\n",
       " u'5657',\n",
       " u'6',\n",
       " u'68',\n",
       " u'7',\n",
       " u'72',\n",
       " u'8',\n",
       " u'80',\n",
       " u'88123',\n",
       " u'8th',\n",
       " u'a',\n",
       " u'ability',\n",
       " u'able',\n",
       " u'about',\n",
       " u'above',\n",
       " u'abstract',\n",
       " u'abstraction',\n",
       " u'accepted',\n",
       " u'accepts',\n",
       " u'accesed',\n",
       " u'access',\n",
       " u'accessed',\n",
       " u'accessible',\n",
       " u'accessing',\n",
       " u'accessmodifier',\n",
       " u'accessspecifications',\n",
       " u'accessspecifiers',\n",
       " u'accomplish',\n",
       " u'according',\n",
       " u'accordingly',\n",
       " u'account',\n",
       " u'accurate',\n",
       " u'achieved',\n",
       " u'acknowledged',\n",
       " u'acordingly',\n",
       " u'across',\n",
       " u'act',\n",
       " u'acted',\n",
       " u'actions',\n",
       " u'activity',\n",
       " u'actual',\n",
       " u'actually',\n",
       " u'ad',\n",
       " u'add',\n",
       " u'added',\n",
       " u'adding',\n",
       " u'addition',\n",
       " u'additional',\n",
       " u'address',\n",
       " u'addressed',\n",
       " u'addresses',\n",
       " u'adds',\n",
       " u'adjacent',\n",
       " u'adjust',\n",
       " u'adjusted',\n",
       " u'adt',\n",
       " u'advance',\n",
       " u'advantage',\n",
       " u'advantages',\n",
       " u'advises',\n",
       " u'affect',\n",
       " u'affected',\n",
       " u'affecting',\n",
       " u'affects',\n",
       " u'after',\n",
       " u'again',\n",
       " u'against',\n",
       " u'agian',\n",
       " u'algorithm',\n",
       " u'algorithms',\n",
       " u'algorithyms',\n",
       " u'alias',\n",
       " u'all',\n",
       " u'allocate',\n",
       " u'allocated',\n",
       " u'allocation',\n",
       " u'allot',\n",
       " u'allow',\n",
       " u'allowed',\n",
       " u'allowing',\n",
       " u'allows',\n",
       " u'almost',\n",
       " u'along',\n",
       " u'already',\n",
       " u'also',\n",
       " u'alter',\n",
       " u'altered',\n",
       " u'alternate',\n",
       " u'alternative',\n",
       " u'always',\n",
       " u'ammout',\n",
       " u'among',\n",
       " u'amonts',\n",
       " u'amount',\n",
       " u'amounts',\n",
       " u'amout',\n",
       " u'ampersand',\n",
       " u'an',\n",
       " u'ancestor',\n",
       " u'ancestors',\n",
       " u'and',\n",
       " u'another',\n",
       " u'answer',\n",
       " u'answered',\n",
       " u'answers',\n",
       " u'anther',\n",
       " u'any',\n",
       " u'anything',\n",
       " u'anytime',\n",
       " u'anywhere',\n",
       " u'appear',\n",
       " u'application',\n",
       " u'applications',\n",
       " u'applied',\n",
       " u'approach',\n",
       " u'appropriate',\n",
       " u'aptr',\n",
       " u'arangment',\n",
       " u'arbitrary',\n",
       " u'architecture',\n",
       " u'are',\n",
       " u'area',\n",
       " u'argument',\n",
       " u'arguments',\n",
       " u'around',\n",
       " u'arranged',\n",
       " u'array',\n",
       " u'arraybased',\n",
       " u'arrayname',\n",
       " u'arrayptr',\n",
       " u'arrays',\n",
       " u'arraysize',\n",
       " u'arriving',\n",
       " u'as',\n",
       " u'assessment',\n",
       " u'assigned',\n",
       " u'assigning',\n",
       " u'assigns',\n",
       " u'associated',\n",
       " u'assume',\n",
       " u'assuming',\n",
       " u'at',\n",
       " u'atleast',\n",
       " u'atributes',\n",
       " u'attach',\n",
       " u'attached',\n",
       " u'attaching',\n",
       " u'attatched',\n",
       " u'attempt',\n",
       " u'attribute',\n",
       " u'attributes',\n",
       " u'attrubutes',\n",
       " u'autocreate',\n",
       " u'automatic',\n",
       " u'automatically',\n",
       " u'available',\n",
       " u'avariable',\n",
       " u'average',\n",
       " u'avl',\n",
       " u'avoid',\n",
       " u'avoiding',\n",
       " u'avoids',\n",
       " u'away',\n",
       " u'awesome',\n",
       " u'b',\n",
       " u'back',\n",
       " u'backtrack',\n",
       " u'backup',\n",
       " u'backward',\n",
       " u'backwards',\n",
       " u'badly',\n",
       " u'balanced',\n",
       " u'bank',\n",
       " u'base',\n",
       " u'based',\n",
       " u'bases',\n",
       " u'basic',\n",
       " u'basically',\n",
       " u'basics',\n",
       " u'basis',\n",
       " u'be',\n",
       " u'because',\n",
       " u'become',\n",
       " u'becomes',\n",
       " u'been',\n",
       " u'before',\n",
       " u'begin',\n",
       " u'beging',\n",
       " u'begining',\n",
       " u'beginning',\n",
       " u'begins',\n",
       " u'behavior',\n",
       " u'behaviors',\n",
       " u'behaviour',\n",
       " u'behind',\n",
       " u'being',\n",
       " u'believe',\n",
       " u'belong',\n",
       " u'belonging',\n",
       " u'below',\n",
       " u'benefit',\n",
       " u'besides',\n",
       " u'best',\n",
       " u'bestcase',\n",
       " u'better',\n",
       " u'between',\n",
       " u'beyond',\n",
       " u'bidimensional',\n",
       " u'big',\n",
       " u'bigger',\n",
       " u'biggest',\n",
       " u'bigo',\n",
       " u'bigoh',\n",
       " u'bin',\n",
       " u'binary',\n",
       " u'bit',\n",
       " u'bits',\n",
       " u'blah',\n",
       " u'block',\n",
       " u'blocks',\n",
       " u'bodies',\n",
       " u'body',\n",
       " u'both',\n",
       " u'bothe',\n",
       " u'bottom',\n",
       " u'bounds',\n",
       " u'bpointer',\n",
       " u'bptr',\n",
       " u'brackets',\n",
       " u'brain',\n",
       " u'branch',\n",
       " u'branched',\n",
       " u'branches',\n",
       " u'branching',\n",
       " u'break',\n",
       " u'breaking',\n",
       " u'breaks',\n",
       " u'brief',\n",
       " u'briefly',\n",
       " u'brings',\n",
       " u'broken',\n",
       " u'bugs',\n",
       " u'build',\n",
       " u'building',\n",
       " u'built',\n",
       " u'burn',\n",
       " u'but',\n",
       " u'by',\n",
       " u'bydimensional',\n",
       " u'byte',\n",
       " u'bytes',\n",
       " u'c',\n",
       " u'calculate',\n",
       " u'calculations',\n",
       " u'call',\n",
       " u'called',\n",
       " u'caller',\n",
       " u'calling',\n",
       " u'calls',\n",
       " u'can',\n",
       " u'candidate',\n",
       " u'cannot',\n",
       " u'cant',\n",
       " u'capable',\n",
       " u'carry',\n",
       " u'case',\n",
       " u'case1',\n",
       " u'casen',\n",
       " u'cases',\n",
       " u'cast',\n",
       " u'cause',\n",
       " u'causes',\n",
       " u'causing']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    path = get_file('shortAnswerGrading-v-2-0.zip',origin='http://web.eecs.umich.edu/~mihalcea/downloads/ShortAnswerGrading_v2.0.zip')\n",
    "except:\n",
    "    print \"error while downloading file\"\n",
    "    \n",
    "    \n",
    "archive = zipfile.ZipFile(path,'r')\n",
    "    \n",
    "questions = archive.read('data/sent/questions') \n",
    "answers = archive.read('data/sent/answers')\n",
    "student_answers = archive.read('data/sent/all') \n",
    "\n",
    "dic1,dic2 = parseData(questions,answers,student_answers)\n",
    "\n",
    "\n",
    "data = parseIntoExamples(dic1,dic2)\n",
    "\n",
    "#print data[0]\n",
    "\n",
    "vocab = set()\n",
    "for (a,b,c,_) in data:\n",
    "    for x in [a,b,c]:\n",
    "        vocab.update(x)\n",
    "vocab=sorted(list(vocab))\n",
    "\n",
    "print len(vocab)\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "word_idx = dict((c,i+1) for i,c in enumerate(vocab))\n",
    "question_maxsize = max((len(x) for x,_,_,_ in data))\n",
    "answer_stud_maxsize = max(len(x) for _,_,x,_ in data)\n",
    "answer_maxsize = max((len(x) for _,x,_,_ in data))\n",
    "\n",
    "vocab[0:300]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A faire:\n",
    "- Nettoyer le vocabulaire pour diminuer sa taille, synonymes, lowercase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Mettons tout ça dans des matrices\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "def vectorize(data,wordidx,qmaxlen,amaxlen):\n",
    "    X,Xs,Y = list(),list(),list()\n",
    "    \n",
    "    lookup = lambda m : wordidx[m]\n",
    "    \n",
    "    for question, _ , student_answer, score in data:\n",
    "        X.append(map(lookup,question))\n",
    "        Xs.append(map(lookup,student_answer))\n",
    "        Y.append(score)\n",
    "        \n",
    "    return pad_sequences(X, maxlen=qmaxlen), pad_sequences(Xs, maxlen=amaxlen), np.array(Y)\n",
    "        \n",
    "    \n",
    "X,Xq,Y = vectorize(data,word_idx,question_maxsize,answer_stud_maxsize)\n",
    "#X_test,Xq_test,Y_test = vectorize(test,word_idx,story_max,question_max)\n",
    "#X_val,Xq_val,Y_val = vectorize(validation,word_idx,story_max,question_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0 2176 1040   38  832 1464]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0 2176 1040   38  832 1464]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0 2176 1040   38  832 1464]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0 2176 1040   38  832 1464]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0 2176 1040   38  832 1464]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0 2176 1040   38  832 1464]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0 2176 1040   38  832 1464]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0 2176 1040   38  832 1464]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0 2176 1040   38  832 1464]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0 2176 1040   38  832 1464]]\n",
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0   38 1464 2016 1468 2050 2018 1230   76 1333 2018  217 1411\n",
      "  1333   38  835 1509 1267 2018 1464 1468 2050 2018  832 1860 1048  287\n",
      "   208  283 2050  722]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0   38  832 1464 1040   38 1464 2016  423 2018   76 1333\n",
      "  2018  832  949 1230]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0  832 1466  148 1466  922  620 2136 2184 1462 2050 2018\n",
      "    76 1333   38  832]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0   38 1464 2050   38  832 1040 2018   76 2181 2018  337\n",
      "   811 2018  832 1695]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0 2029  287  208 1418 2050  835 1714  826  835 1933  949  158  128\n",
      "   163 2050 1380 1466]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0 1048  423 2018   76 1333\n",
      "  2018  832  949 1230]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0 2178 1048 1040  535   38  832 1464  286 1064  832 2197\n",
      "  2222 1368 1259  151]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0   38\n",
      "  1464 2050   38  832]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0   38 1464\n",
      "  2050   38  832 1065  423 2018   76 1333 2018  832  128  287  208 2120\n",
      "  2050  282 2016  832]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0  832 1466  148 1466  922  620 2136 2184 1462 2050 2018\n",
      "    76 1333   38  832]]\n",
      "[ 1.   1.   1.   1.   1.   0.7  0.7  1.   1.   1. ]\n"
     ]
    }
   ],
   "source": [
    "print X[0:10]\n",
    "print Xq[0:10]\n",
    "print Y[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_17 (Embedding)         (None, 35, 50)        111150                                       \n",
      "____________________________________________________________________________________________________\n",
      "embedding_18 (Embedding)         (None, 74, 50)        111150                                       \n",
      "____________________________________________________________________________________________________\n",
      "lstm_14 (LSTM)                   (None, 50)            20200                                        \n",
      "____________________________________________________________________________________________________\n",
      "repeatvector_8 (RepeatVector)    (None, 35, 50)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_15 (LSTM)                   (None, 50)            30200       merge_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 1)             51          lstm_15[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 1)             0           dense_6[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 272751\n",
      "____________________________________________________________________________________________________\n",
      "Epoch 1/25\n",
      " 576/2442 [======>.......................] - ETA: 17s - loss: 0.0803 - acc: 0.4705"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2223 is out of bounds for size 2223\nApply node that caused the error: AdvancedSubtensor1(embedding_18_W, Reshape{1}.0)\nToposort index: 96\nInputs types: [TensorType(float32, matrix), TensorType(int32, vector)]\nInputs shapes: [(2223, 50), (4736,)]\nInputs strides: [(200, 4), (4,)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[Reshape{2}(AdvancedSubtensor1.0, TensorConstant{[-1 50]})]]\n\nBacktrace when the node is created(use Theano flag traceback.limit=N to make it longer):\n  File \"<ipython-input-61-f1aaa27707d9>\", line 18, in <module>\n    ans_model.add(Embedding(vocab_size,embed_size,input_length=answer_stud_maxsize))\n  File \"/usr/lib/python2.7/site-packages/keras/models.py\", line 114, in add\n    layer.create_input_layer(batch_input_shape, input_dtype)\n  File \"/usr/lib/python2.7/site-packages/keras/engine/topology.py\", line 341, in create_input_layer\n    self(x)\n  File \"/usr/lib/python2.7/site-packages/keras/engine/topology.py\", line 485, in __call__\n    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)\n  File \"/usr/lib/python2.7/site-packages/keras/engine/topology.py\", line 543, in add_inbound_node\n    Node.create_node(self, inbound_layers, node_indices, tensor_indices)\n  File \"/usr/lib/python2.7/site-packages/keras/engine/topology.py\", line 148, in create_node\n    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))\n  File \"/usr/lib/python2.7/site-packages/keras/layers/embeddings.py\", line 135, in call\n    out = K.gather(W, x)\n  File \"/usr/lib/python2.7/site-packages/keras/backend/theano_backend.py\", line 165, in gather\n    return reference[indices]\n\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-f1aaa27707d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    427\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m                               sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m   1106\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1108\u001b[0;31m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[1;32m   1109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[1;32m    824\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    827\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    869\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[1;32m    872\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m                 \u001b[0;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[0;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;31m# extra long error message in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m     \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2223 is out of bounds for size 2223\nApply node that caused the error: AdvancedSubtensor1(embedding_18_W, Reshape{1}.0)\nToposort index: 96\nInputs types: [TensorType(float32, matrix), TensorType(int32, vector)]\nInputs shapes: [(2223, 50), (4736,)]\nInputs strides: [(200, 4), (4,)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[Reshape{2}(AdvancedSubtensor1.0, TensorConstant{[-1 50]})]]\n\nBacktrace when the node is created(use Theano flag traceback.limit=N to make it longer):\n  File \"<ipython-input-61-f1aaa27707d9>\", line 18, in <module>\n    ans_model.add(Embedding(vocab_size,embed_size,input_length=answer_stud_maxsize))\n  File \"/usr/lib/python2.7/site-packages/keras/models.py\", line 114, in add\n    layer.create_input_layer(batch_input_shape, input_dtype)\n  File \"/usr/lib/python2.7/site-packages/keras/engine/topology.py\", line 341, in create_input_layer\n    self(x)\n  File \"/usr/lib/python2.7/site-packages/keras/engine/topology.py\", line 485, in __call__\n    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)\n  File \"/usr/lib/python2.7/site-packages/keras/engine/topology.py\", line 543, in add_inbound_node\n    Node.create_node(self, inbound_layers, node_indices, tensor_indices)\n  File \"/usr/lib/python2.7/site-packages/keras/engine/topology.py\", line 148, in create_node\n    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))\n  File \"/usr/lib/python2.7/site-packages/keras/layers/embeddings.py\", line 135, in call\n    out = K.gather(W, x)\n  File \"/usr/lib/python2.7/site-packages/keras/backend/theano_backend.py\", line 165, in gather\n    return reference[indices]\n\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "#Model\n",
    "\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Dense, Merge,RepeatVector,Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "\n",
    "\n",
    "embed_size = 50\n",
    "batch_size=64\n",
    "epochs=25\n",
    "\n",
    "question_model = Sequential()\n",
    "question_model.add(Embedding(vocab_size,embed_size,input_length=question_maxsize))\n",
    "\n",
    "ans_model = Sequential()\n",
    "ans_model.add(Embedding(vocab_size,embed_size,input_length=answer_stud_maxsize))\n",
    "ans_model.add(LSTM(embed_size))\n",
    "ans_model.add(RepeatVector(question_maxsize)) #permet d'ajuster la taille du modèle afin de préparer un merge\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Merge([question_model, ans_model], mode='concat'))\n",
    "model.add(LSTM(embed_size))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.01),loss='mse',metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = model.fit([X, Xq], Y, batch_size=batch_size, nb_epoch=epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
