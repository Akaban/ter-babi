{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-9702dd9b3a10>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-9702dd9b3a10>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    Notebook de la semaine du 22/03\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Projet: Facebook BaBi tasks\n",
    "Notebook de la semaine du 22/03\n",
    "Par Thierry Loesch et Bryce Tichit\n",
    "\n",
    "Dernier notebook\n",
    "\n",
    "Comme demandé par notre tuteur, nous allons désormais essayer d'adapter les travaux fait jusqu'ici sur un autre projet sensiblement identique.\n",
    "\n",
    "-----------------------------------\n",
    "\n",
    "5.1  Notation automatique de réponses courtes à des questions\n",
    "\n",
    "Les données sont ici pour le téléchargement et leur description est dans cet article\n",
    "\n",
    "Lorsque l'on connait:\n",
    "\n",
    "    une question,\n",
    "    une réponse d'un étudiant,\n",
    "    la bonne réponse, \n",
    "\n",
    "comment prédire la note à donné à la réponse de l'étudiant. Il peut être aussi intéressant d'essayer d'apprendre à générer la réponse. \n",
    "\n",
    "--------------------------\n",
    "\n",
    "On cherchera en premier à prédire la note de l'étudiant, le réseau devra rendre un réel. Normaliser les notes (les mettre entre 0 et 1) et activation par Sigmoid (output entre 0 et 1) afin de prédire la note."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from keras.utils.data_utils import get_file\n",
    "import zipfile\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "#import gensim\n",
    "#from gensim import models\n",
    "\n",
    "def tokenize(sent):\n",
    "    \n",
    "    def remPunctuation(sent):\n",
    "        return \"\".join(l for l in sent if l not in string.punctuation)\n",
    "        \n",
    "    return [x.strip() for x in re.split('(\\W+)?', remPunctuation(sent.lower())) if x.strip()]\n",
    "\n",
    "def parseData(questions,answers,student_answers=''):\n",
    "    \n",
    "    #questions_data = dict() #ce dictionnaire contiendra les tuples (question,answer) indexés par la clé \"numéro de question\"\n",
    "    \n",
    "    questions_data = dict()\n",
    "    \n",
    "    for line in questions.split('\\n'): #une ligne = une question\n",
    "        line = line.decode('utf-8').strip()\n",
    "        try:\n",
    "            index,question = line.split(' ',1)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        questions_data[index] = [question.replace('<STOP>',''),None]\n",
    "    \n",
    "    for line in answers.split('\\n'):\n",
    "        line = line.decode('utf-8').strip()\n",
    "        \n",
    "        try:\n",
    "            index,answer = line.split(' ',1)\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        questions_data[index][1] = answer.replace('<STOP>','')\n",
    "        \n",
    "    questions_data = {k: tuple(map(tokenize,v)) for k, v in questions_data.items()}\n",
    "    \n",
    "    stud_ans = dict()\n",
    "    \n",
    "    for line in student_answers.split('\\n'):\n",
    "        line = line.decode('utf-8')\n",
    "        try:\n",
    "            index,ans = line.split(' ',1)\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        answers=ans.split('<STOP>')\n",
    "        answers=[a for a in answers if a]\n",
    "            \n",
    "        if index in stud_ans:\n",
    "            stud_ans[index] += map(tokenize,answers)\n",
    "        else:\n",
    "            stud_ans[index] = map(tokenize,answers)\n",
    "    \n",
    "    return questions_data,stud_ans\n",
    "        \n",
    "    \n",
    "def parseIntoExamples(qd,sa):\n",
    "    \n",
    "    ret = list()\n",
    "    \n",
    "    for index,q_a in qd.items():\n",
    "        scores = [k for k in archive.read('data/scores/'+str(index+'/ave')).split('\\n') if k]\n",
    "        for stud_ans,score in zip(sa[index],scores):\n",
    "            ret.append((q_a[0],q_a[1],stud_ans,float(score)/5.))\n",
    "    return ret\n",
    "\n",
    "#print 'loading'\n",
    "#model = gensim.models.KeyedVectors.load_word2vec_format('G:/GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "#print 'done'\n",
    "                       \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2223\n",
      "1290\n",
      "2223\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import chain\n",
    "\n",
    "try:\n",
    "    path = get_file('shortAnswerGrading-v-2-0.zip',origin='http://web.eecs.umich.edu/~mihalcea/downloads/ShortAnswerGrading_v2.0.zip')\n",
    "except:\n",
    "    print \"error while downloading file\"\n",
    "    \n",
    "    \n",
    "archive = zipfile.ZipFile(path,'r')\n",
    "    \n",
    "questions = archive.read('data/sent/questions') \n",
    "answers = archive.read('data/sent/answers')\n",
    "student_answers = archive.read('data/sent/all') \n",
    "\n",
    "dic1,dic2 = parseData(questions,answers,student_answers)\n",
    "\n",
    "\n",
    "data = parseIntoExamples(dic1,dic2)\n",
    "\n",
    "nbSamples = len(data)\n",
    "\n",
    "data_train = data[0:nbSamples/2]\n",
    "data_test = data[(nbSamples/2):-1]\n",
    "\n",
    "#print data[0]\n",
    "\n",
    "vocab = set()\n",
    "for (a,b,c,_) in data:\n",
    "    for x in [a,b,c]:\n",
    "        vocab.update(x)\n",
    "vocab=sorted(list(vocab))\n",
    "\n",
    "grouped_vocab = defaultdict(list)\n",
    "for w in vocab:\n",
    "    synonyms = wordnet.synsets(w)\n",
    "    lemmas = set(chain.from_iterable([word.lemma_names() for word in synonyms]))\n",
    "    intersection = list(set(lemmas) & set(grouped_vocab.keys()))\n",
    "    if intersection == []:\n",
    "        grouped_vocab[w].append(w)\n",
    "    else:\n",
    "        for v in intersection:\n",
    "            if (v in grouped_vocab.keys()):\n",
    "                grouped_vocab[v].append(w)\n",
    "\n",
    "for k in grouped_vocab:\n",
    "    grouped_vocab[k] = list(set(grouped_vocab[k]))\n",
    "    #grouped_vocab[k].insert(0 , grouped_vocab[k].pop(grouped_vocab[k].index(k)))\n",
    "\n",
    "vocab_word_to_synonym = {}\n",
    "for k in grouped_vocab:\n",
    "    for v in grouped_vocab[k]:\n",
    "        vocab_word_to_synonym[v]=k\n",
    "        \n",
    "\n",
    "print len(vocab)\n",
    "print len(grouped_vocab)\n",
    "print len(vocab_word_to_synonym)\n",
    "#print vocab_word_to_synonym\n",
    "\n",
    "vocab_size = len(vocab) +1\n",
    "word_idx_before_synonyms = dict((c,i+1) for i,c in enumerate(vocab))\n",
    "word_idx = vocab_word_to_synonym\n",
    "for k in word_idx:\n",
    "    word_idx[k] = word_idx_before_synonyms[word_idx[k]]\n",
    "question_maxsize = max((len(x) for x,_,_,_ in data))\n",
    "answer_stud_maxsize = max(len(x) for _,_,x,_ in data)\n",
    "answer_maxsize = max((len(x) for _,x,_,_ in data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a créé un dictionnaire grouped_vocab de listes, qui regroupe les mots du vocabulaire autour d'un même synonyme.\n",
    "Et le dictionnaire vocab_word_to_synonym, qui pour chaque mot du vocabulaire lui associe son synonyme en valeur.\n",
    "\n",
    "A faire:\n",
    "- On pourrait encore faire du stemming pour augmenter le nombre d'association et réduire d'avantage le vocabulaire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Mettons tout ça dans des matrices\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "#précision de 50% avec question , stud_answer , score\n",
    "\n",
    "def vectorize(data,wordidx,qmaxlen,amaxlen):\n",
    "    X,Xs,Y = list(),list(),list()\n",
    "    \n",
    "    lookup = lambda m : wordidx[m]\n",
    "    \n",
    "    for question, ans , student_answer, score in data:\n",
    "        X.append(map(lookup,ans))\n",
    "        Xs.append(map(lookup,student_answer))\n",
    "        Y.append(score)\n",
    "        \n",
    "    return pad_sequences(X, maxlen=qmaxlen), pad_sequences(Xs, maxlen=amaxlen), np.array(Y)      \n",
    "    \n",
    "X,Xq,Y = vectorize(data_train,word_idx,answer_maxsize,answer_stud_maxsize)\n",
    "X_test,Xq_test,Y_test = vectorize(data_test,word_idx,answer_maxsize,answer_stud_maxsize)\n",
    "#X_test,Xq_test,Y_test = vectorize(test,word_idx,story_max,question_max)\n",
    "#X_val,Xq_val,Y_val = vectorize(validation,word_idx,story_max,question_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0 2018\n",
      "    76 1333 2018 1162  949 1230 2181 2018  832  337 1695]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0 2018\n",
      "    76 1333 2018 1162  949 1230 2181 2018  832  337 1695]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0 2018\n",
      "    76 1333 2018 1162  949 1230 2181 2018  832  337 1695]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0 2018\n",
      "    76 1333 2018 1162  949 1230 2181 2018  832  337 1695]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0 2018\n",
      "    76 1333 2018 1162  949 1230 2181 2018  832  337 1695]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0 2018\n",
      "    76 1333 2018 1162  949 1230 2181 2018  832  337 1695]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0 2018\n",
      "    76 1333 2018 1162  949 1230 2181 2018  832  337 1695]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0 2018\n",
      "    76 1333 2018 1162  949 1230 2181 2018  832  337 1695]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0 2018\n",
      "    76 1333 2018 1162  949 1230 2181 2018  832  337 1695]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0 2018\n",
      "    76 1333 2018 1162  949 1230 2181 2018  832  337 1695]]\n",
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0   38 1464 2016  603 2050 2018 1230   76 1333 2018  214  832\n",
      "  1333   38  832  764 1267 2018 1464  603 2050 2018  832 1860 1048  222\n",
      "   208   76 2050   55]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0   38  832 1464  208   38 1464 2016  292 2018   76 1333\n",
      "  2018  832  949 1230]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0  832 1464  148 1464    5  620 2135 2184  603 2050 2018\n",
      "    76 1333   38  832]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0   38 1464 2050   38  832  208 2018   76 2181 2018  337\n",
      "   811 2018  832 1695]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0 2029  222  208 1103 2050  832  845  826  832 1933  949  154  128\n",
      "   104 2050  625 1464]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0 1048  292 2018   76 1333\n",
      "  2018  832  949 1230]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0 2178 1048  208  535   38  832 1464   76 1064  832 2197\n",
      "  1317 1368 1259  150]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0   38\n",
      "  1464 2050   38  832]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0   38 1464\n",
      "  2050   38  832 1065  292 2018   76 1333 2018  832  128  222  208 1493\n",
      "  2050   76 2016  832]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0  832 1464  148 1464    5  620 2135 2184  603 2050 2018\n",
      "    76 1333   38  832]]\n",
      "[ 1.   1.   1.   1.   1.   0.7  0.7  1.   1.   1. ]\n"
     ]
    }
   ],
   "source": [
    "print X[0:10]\n",
    "print Xq[0:10]\n",
    "print Y[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modele\n",
    "\n",
    "Il s'agit du même modèle que pour les babi-tasks mais legèrement modifié, voir ce qu'on peut tenter comme modèle (question? answer? stud_answer?) mais à priori garder la même architecture.\n",
    "\n",
    "Actuellement les performances sont faibles à cause de la taille du vocabulaire (embed_size trop petit pour sa taille) il faut augmenter l'embed_size de manière raisonnable mais aussi diminuer la taille du vocabulaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Users\\ABE\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:25: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "merge_1 (Merge)              (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 201       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 605,801\n",
      "Trainable params: 605,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Users\\ABE\\Anaconda2\\lib\\site-packages\\keras\\models.py:834: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1221/1221 [==============================] - 7s - loss: 0.0926 - acc: 0.4545     \n",
      "Epoch 2/10\n",
      "1221/1221 [==============================] - 9s - loss: 0.0562 - acc: 0.4914     \n",
      "Epoch 3/10\n",
      "1221/1221 [==============================] - 10s - loss: 0.0473 - acc: 0.4914    \n",
      "Epoch 4/10\n",
      "1221/1221 [==============================] - 12s - loss: 0.0424 - acc: 0.4914    \n",
      "Epoch 5/10\n",
      "1221/1221 [==============================] - 13s - loss: 0.0387 - acc: 0.4914    \n",
      "Epoch 6/10\n",
      "1221/1221 [==============================] - 14s - loss: 0.0358 - acc: 0.4939    \n",
      "Epoch 7/10\n",
      "1221/1221 [==============================] - 16s - loss: 0.0333 - acc: 0.4930    \n",
      "Epoch 8/10\n",
      "1221/1221 [==============================] - 20s - loss: 0.0313 - acc: 0.4955    \n",
      "Epoch 9/10\n",
      "1221/1221 [==============================] - 21s - loss: 0.0291 - acc: 0.4955    \n",
      "Epoch 10/10\n",
      "1221/1221 [==============================] - 22s - loss: 0.0263 - acc: 0.4963    \n"
     ]
    }
   ],
   "source": [
    "#Model\n",
    "\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Dense, Merge,RepeatVector,Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "\n",
    "\n",
    "embed_size = 100\n",
    "batch_size=256\n",
    "epochs=10\n",
    "\n",
    "question_model = Sequential()\n",
    "question_model.add(Embedding(vocab_size,embed_size,input_length=answer_maxsize))\n",
    "question_model.add(LSTM(embed_size))\n",
    "\n",
    "ans_model = Sequential()\n",
    "ans_model.add(Embedding(vocab_size,embed_size,input_length=answer_stud_maxsize))\n",
    "ans_model.add(LSTM(embed_size))\n",
    "#ans_model.add(RepeatVector(answer_maxsize)) #permet d'ajuster la taille du modèle afin de préparer un merge\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Merge([question_model, ans_model], mode='concat',concat_axis=1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.01),loss='mse',metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = model.fit([X, Xq], Y, batch_size=batch_size, nb_epoch=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plotLearningCurves_acc(history_model,save=''):\n",
    "    plt.plot(history_model.history['acc'])\n",
    "    plt.plot(history_model.history['val_acc'])\n",
    "    plt.title('Precision du modele')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    if save:\n",
    "        plt.savefig(save,bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "def plotLearningCurves_loss(history_model,save=''):\n",
    "    plt.plot(history_model.history['loss'])\n",
    "    plt.plot(history_model.history['val_loss'])\n",
    "    plt.title('Perte sur le modele')\n",
    "    plt.ylabel('Perte')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    if save:\n",
    "        plt.savefig(save,bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1220/1220 [==============================] - 5s     \n",
      "\n",
      "Perte = 0.068\n",
      "Précision = 51%\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'val_acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0f3b7b725595>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Précision = {:.0f}%\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mplotLearningCurves_acc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplotLearningCurves_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-0b2c926f7fee>\u001b[0m in \u001b[0;36mplotLearningCurves_acc\u001b[0;34m(history_model, save)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplotLearningCurves_acc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Precision du modele'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Precision'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val_acc'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1876zckxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29467400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Calcul de précision sur l'ensemble de test\n",
    "\n",
    "loss,acc = model.evaluate([X_test,Xq_test],Y_test, batch_size=batch_size)\n",
    "print \"\\nPerte = {:.3f}\".format(loss)\n",
    "print \"Précision = {:.0f}%\".format(acc*100)\n",
    "\n",
    "plotLearningCurves_acc(history)\n",
    "\n",
    "plotLearningCurves_loss(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
